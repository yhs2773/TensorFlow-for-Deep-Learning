{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPC1pOidclZW1H787cd+Asa"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# ðŸ›  Exercises"],"metadata":{"id":"1FttDoOsA5Bg"}},{"cell_type":"markdown","source":["## 1. Rebuild, compile, and train `model_1`, `model_2`, and `model_5` using the [Keras Sequential API](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential) instead of the Functional API."],"metadata":{"id":"iVPOiQaGA62a"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wxz3N0PzAzot"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["## 2. Retrain the baseline model with 10% of the training data. How does perform compared to the Universal Sentence Encoder model with 10% of the training data?"],"metadata":{"id":"YlBUtBFwBAR5"}},{"cell_type":"code","source":[],"metadata":{"id":"lJO5PsE5BDWy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 3. Try fine-tuning the TF Hub Universal Sentence Encoder model by setting `training=True` when instantiating it as a Keras layer.\n","```\n","We can use this encoding layer in place of our text_vectorizer and embedding layer\n","\n","sentence_encoder_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n","                                        input_shape=[],\n","                                        dtype=tf.string,\n","                                        trainable=True) # turn training on to fine-tune the TensorFlow Hub model\n","```"],"metadata":{"id":"3FeZvN_iBDwc"}},{"cell_type":"code","source":[],"metadata":{"id":"GNiM5uTbBRy5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4. Retrain the best model you've got so far on the whole training set (no validation split). Then use this trained model to make predictions on the test dataset and format the predictions into the same format as the `sample_submission.csv` file from Kaggle (see the Files tab in Colab for what the `sample_submission.csv` file looks like). Once you've done this, [submit it to the Kaggle competition](https://www.kaggle.com/c/nlp-getting-started/data), how did your model perform?"],"metadata":{"id":"2DuOqYf9BSVo"}},{"cell_type":"code","source":[],"metadata":{"id":"slw4Tl07BbaZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 5. Combine the ensemble predictions using the majority vote (mode), how does this perform compared to averaging the prediction probabilities of each model?"],"metadata":{"id":"IKoLa5gkBb-X"}},{"cell_type":"code","source":[],"metadata":{"id":"W3KijYLTBhr6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 6. Make a confusion matrix with the best-performing model's predictions on the validation set and the validation ground truth labels."],"metadata":{"id":"jvPj1JsjBiBC"}},{"cell_type":"code","source":[],"metadata":{"id":"ZJ-lGZPJBmWp"},"execution_count":null,"outputs":[]}]}