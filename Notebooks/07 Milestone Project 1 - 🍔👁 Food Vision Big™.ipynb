{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOayko9s3/rwxbfk56GT9a5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 07 Milestone Project 1: 🍔👁 Food Vision Big™\n","\n","In the previous notebook ([transfer learning part 3: scaling up](https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/06_transfer_learning_in_tensorflow_part_3_scaling_up.ipynb)) we built Food Vision mini: a transfer learning model that beat the original results of the [Food101 paper](https://data.vision.ee.ethz.ch/cvl/datasets_extra/food-101/) with only 10% of the data.\n","\n","But you might be wondering, what would happen if we used all the data?\n","\n","Well, that's what we're going to find out in this notebook!\n","\n","We're going to be building Food Vision Big™, using all of the data from the Food101 dataset.\n","\n","Yep. All 75,750 training images and 25,250 testing images.\n","\n","And guess what...\n","\n","This time [**we've got the goal of beating DeepFood**](https://www.researchgate.net/publication/304163308_DeepFood_Deep_Learning-Based_Food_Image_Recognition_for_Computer-Aided_Dietary_Assessment), a 2016 paper which used a Convolutional Neural Network trained for 2-3 days to achieve 77.4% top-1 accuracy.\n","\n","> 🔑 Note: Top-1 accuracy means \"accuracy for the top softmax activation value output by the model\" (because softmax outputs a value for every class, but top-1 means only the highest one is evaluated). Top-5 accuracy means \"accuracy for the top 5 softmax activation values output by the model\", in other words, did the true label appear in the top 5 activation values? Top-5 accuracy scores are usually noticeably higher than top-1.\n","\n","|\t|🍔👁 Food Vision Big™|🍔👁 Food Vision mini|\n","|--|--|--|\n","|Dataset source|TensorFlow Datasets|Preprocessed download from Kaggle\n","|Train data|75,750 images|7,575 images\n","|Test data|25,250 images|25,250 images\n","|Mixed precision|Yes|No\n","|Data loading|Performanant tf.data API|TensorFlow pre-built function\n","|Target results|77.4% top-1 accuracy (beat [DeepFood paper](https://arxiv.org/abs/1606.05675))|50.76% top-1 accuracy (beat [Food101 paper](https://data.vision.ee.ethz.ch/cvl/datasets_extra/food-101/static/bossard_eccv14_food-101.pdf))|\n","\n","*Table comparing the difference between Food Vision Big (this notebook) versus Food Vision mini (previous notebook).*\n","\n","Alongside attempting to beat the DeepFood paper, we're going to learn about two methods to significantly improve the speed of our model training:\n","\n","Prefetching\n","Mixed precision training\n","But more on these later."],"metadata":{"id":"NXOLMxqh0DBO"}},{"cell_type":"markdown","source":["## What we're going to cover\n","\n","- Using TensorFlow Datasets to download and explore data\n","- Creating a preprocessing function for our data\n","- Batching & preparing datasets for modeling (**making our datasets run fast**)\n","- Creating modeling callbacks\n","- Setting up **mixed precision training**\n","- Building a feature extraction model (see [transfer learning part 1: feature extraction](https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/04_transfer_learning_in_tensorflow_part_1_feature_extraction.ipynb))\n","- Fine-tuning the feature extraction model (see [transfer learning part 2: fine-tuning](https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/05_transfer_learning_in_tensorflow_part_2_fine_tuning.ipynb))\n","- Viewing training results on TensorBoard"],"metadata":{"id":"MUzjbCYH1WyE"}},{"cell_type":"markdown","source":["## Check GPU\n","\n","For this notebook, we're going to be doing something different.\n","\n","We're going to be using mixed precision training.\n","\n","Mixed precision training was introduced in [TensorFlow 2.4.0](https://blog.tensorflow.org/2020/12/whats-new-in-tensorflow-24.html) (a very new feature at the time of writing).\n","\n","What does **mixed precision training** do?\n","\n","Mixed precision training uses a combination of single precision (float32) and half-preicison (float16) data types to speed up model training (up 3x on modern GPUs).\n","\n","We'll talk about this more later on but in the meantime, you can read the [TensorFlow documentation on mixed precision](https://www.tensorflow.org/guide/mixed_precision) for more details.\n","\n","For now, before we can move forward if we want to use mixed precision training, we need to make sure the GPU powering our Google Colab instance (if you're using Google Colab) is compatible.\n","\n","For mixed precision training to work, **you need access to a GPU with a compute compatibility score of 7.0+.**\n","\n","Google Colab offers several kinds of GPU.\n","\n","However, some of them **aren't compatible with mixed precision training.**\n","\n","Therefore to make sure you have access to mixed precision training in Google Colab, you can check your GPU compute capability score on [Nvidia's developer website](https://developer.nvidia.com/cuda-gpus#compute).\n","\n","As of May 2023, the GPUs available on Google Colab which allow mixed precision training are:\n","\n","- NVIDIA A100 (available with Google Colab Pro)\n","- NVIDIA Tesla T4\n","\n","> 🔑 Note: You can run the cell below to check your GPU name and then compare it to [list of GPUs on NVIDIA's developer page](https://developer.nvidia.com/cuda-gpus#compute) to see if it's capable of using mixed precision training."],"metadata":{"id":"-lP-wrEW2M-e"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9Zcw8luNz_N3","executionInfo":{"status":"ok","timestamp":1702448879988,"user_tz":-540,"elapsed":16,"user":{"displayName":"Hee Seong Yang","userId":"11765788859671095501"}},"outputId":"b31a8793-4418-4606-a75e-4e12f4297875"},"outputs":[{"output_type":"stream","name":"stdout","text":["/bin/bash: line 1: nvidia-smi: command not found\n"]}],"source":["# Get GPU name\n","!nvidia-smi -L"]},{"cell_type":"markdown","source":["Since mixed precision training was introduced in TensorFlow 2.4.0, make sure you've got at least TensorFlow 2.4.0+."],"metadata":{"id":"Of5ydes_3EGK"}},{"cell_type":"code","source":["# Note: As of May 2023, there have been some issues with TensorFlow versions 2.9-2.12\n","# with the following code.\n","# However, these seemed to have been fixed in version 2.13+.\n","# TensorFlow version 2.13 is available in tf-nightly as of May 2023 (will be default in Google Colab soon).\n","# Therefore, to prevent errors we'll install tf-nightly first.\n","# See more here: https://github.com/mrdbourke/tensorflow-deep-learning/discussions/550\n","\n","# Install tf-nightly (required until 2.13.0+ is the default in Google Colab)\n","# !pip install -U -q tf-nightly\n","\n","# Check TensorFlow version (should be minimum 2.4.0+ but 2.13.0+ is better)\n","import tensorflow as tf\n","print(f\"TensorFlow version: {tf.__version__}\")\n","\n","# Add timestamp\n","import datetime\n","print(f\"Notebook last run (end-to-end): {datetime.datetime.now()}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ao7Hfr173CVA","executionInfo":{"status":"ok","timestamp":1702448922991,"user_tz":-540,"elapsed":5861,"user":{"displayName":"Hee Seong Yang","userId":"11765788859671095501"}},"outputId":"3db7065a-ab21-4b1f-c033-3d9afa836d88"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["TensorFlow version: 2.14.0\n","Notebook last run (end-to-end): 2023-12-13 06:28:43.776076\n"]}]},{"cell_type":"markdown","source":["## Get helper functions\n","\n","We've created a series of helper functions throughout the previous notebooks in the course. Instead of rewriting them (tedious), we'll import the [`helper_functions.py`](https://github.com/yhs2773/TensorFlow-for-Deep-Learning/blob/main/helper_functions.py) file from the GitHub repo."],"metadata":{"id":"GVbrMm7m3Wy9"}},{"cell_type":"code","source":["# Get helper functions file\n","import os\n","\n","if not os.path.exists(\"helper_functions.py\"):\n","    !wget https://raw.githubusercontent.com/yhs2773/TensorFlow-for-Deep-Learning/main/helper_functions.py\n","else:\n","    print(\"[INFO] 'helper_functions.py' already exists, skipping download.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uYIN4vSe3Oae","executionInfo":{"status":"ok","timestamp":1702449064988,"user_tz":-540,"elapsed":11,"user":{"displayName":"Hee Seong Yang","userId":"11765788859671095501"}},"outputId":"3eefe556-76df-4c5f-eecd-bb42db014701"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-12-13 06:31:05--  https://raw.githubusercontent.com/yhs2773/TensorFlow-for-Deep-Learning/main/helper_functions.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 10872 (11K) [text/plain]\n","Saving to: ‘helper_functions.py’\n","\n","\rhelper_functions.py   0%[                    ]       0  --.-KB/s               \rhelper_functions.py 100%[===================>]  10.62K  --.-KB/s    in 0s      \n","\n","2023-12-13 06:31:05 (98.7 MB/s) - ‘helper_functions.py’ saved [10872/10872]\n","\n"]}]},{"cell_type":"markdown","source":["## Use TensorFlow Datasets to Download Data\n","\n","In previous notebooks, we've downloaded our food images (from the [Food101 dataset](https://www.kaggle.com/dansbecker/food-101/home)) from Google Storage.\n","\n","This is a typical workflow you'd use if you're working on your datasets.\n","\n","However, there's another way to get datasets ready to use with TensorFlow.\n","\n","For many of the most popular datasets in the machine learning world (often referred to and used as benchmarks), you can access them through [TensorFlow Datasets (TFDS)](https://www.tensorflow.org/datasets/overview).\n","\n","What is **TensorFlow Datasets**?\n","\n","A place for prepared and ready-to-use machine learning datasets.\n","\n","Why use TensorFlow Datasets?\n","\n","- Load data already in Tensors\n","- Practice on well established datasets\n","- Experiment with differet data loading techniques (like we're going to use in this notebook)\n","- Experiment with new TensorFlow features quickly (such as mixed precision training)\n","\n","*Why not* use TensorFlow Datasets?\n","\n","- The datasets are static (they don't change like your real-world datasets would)\n","- It might not be suited for your particular problem (but great for experimenting)\n","\n","To begin using TensorFlow Datasets we can import it under the alias `tfds`."],"metadata":{"id":"rkw1p1_o334J"}},{"cell_type":"code","source":["# Get TensorFlow Datasets\n","import tensorflow_datasets as tfds"],"metadata":{"id":"t0Rv8rXT3yfv","executionInfo":{"status":"ok","timestamp":1702449305644,"user_tz":-540,"elapsed":1742,"user":{"displayName":"Hee Seong Yang","userId":"11765788859671095501"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["To find all of the available datasets in TensorFlow Datasets, you can use the `list_builders()` method.\n","\n","After doing so, we can check to see if the one we're after (`\"food101\"`) is present."],"metadata":{"id":"pMVBChGQ42pN"}},{"cell_type":"code","source":["# Get all available datasets in tfds\n","datasets_list = tfds.list_builders()\n","\n","# Set our target dataset and see if it exists\n","target_dataset = \"food101\"\n","print(f\"'{target_dataset}' in TensorFlow Datasets: {target_dataset in datasets_list}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sqEvTYk24sqQ","executionInfo":{"status":"ok","timestamp":1702449435077,"user_tz":-540,"elapsed":1067,"user":{"displayName":"Hee Seong Yang","userId":"11765788859671095501"}},"outputId":"ebd9e801-cb48-4e7c-b656-d22662befa58"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["'food101' in TensorFlow Datasets: True\n"]}]},{"cell_type":"markdown","source":["Beautiful! It looks like the dataset we're after is available (note there are plenty more available but we're on Food101).\n","\n","To get access to the Food101 dataset from the TFDS, we can use the [`tfds.load()`](https://www.tensorflow.org/datasets/api_docs/python/tfds/load) method.\n","\n","In particular, we'll have to pass it a few parameters to let it know what we're after:\n","\n","- `name` (str): the target dataset (e.g. `\"food101\"`)\n","- `split` (list, optional): what splits of the dataset we're after (e.g. `[\"train\", \"validation\"]`)\n","    - the `split` parameter is quite tricky. See the [documentation](https://github.com/tensorflow/datasets/blob/master/docs/splits.md) for more.\n","- `shuffle_files` (bool): whether or not to shuffle the files on download, defaults to `False`\n","- `as_supervised` (bool): `True` to download data samples in tuple format (`(data, label)`) or `False` for dictionary format\n","- `with_info` (bool): `True` to download dataset metadata (labels, number of samples, etc)\n","\n","> 🔑 Note: Calling the `tfds.load()` method will start to download a target dataset to disk if the `download=True` parameter is set (default). This dataset could be 100GB+, so make sure you have space."],"metadata":{"id":"XRyTTyqR5PPX"}},{"cell_type":"code","source":["# Load in the data (takes about 5-6 minutes in Google Colab)\n","(train_data, test_data), ds_info = tfds.load(name=\"food101\",                # target dataset to get from TFDS\n","                                             split=[\"train\", \"validation\"], # what splits of data should we get? note: not all datasets have train, valid, test\n","                                             shuffle_files=True,            # shuffle files on download?\n","                                             as_supervised=True,            # download data in tuple format (sample, label), e.g. (image, label)\n","                                             with_info=True)                # include dataset metadata? if so, tfds.load() returns tuple (data, ds_info)"],"metadata":{"id":"_XTEarki5Mpv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Wonderful! After a few minutes of downloading, we've now got access to the entire Food101 dataset (in tensor format) ready for modeling.\n","\n","Now let's get a little information from our dataset, starting with the class names.\n","\n","Getting class names from a TensorFlow Datasets dataset requires downloading the `\"dataset_info\"` variable (by using the `as_supervised=True` parameter in the `tfds.load()` method, **note**: this will only work for supervised datasets in TFDS).\n","\n","We can access the class names of a particular dataset using the `dataset_info.features` attribute and accessing `names` attribute of the the `\"label\"` key."],"metadata":{"id":"AI5ya-_a6jUc"}},{"cell_type":"code","source":["# Features of Food101 TFDS\n","ds_info.features"],"metadata":{"id":"LgGZjnuF69QF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Get class names\n","class_names = ds_info.features[\"label\"].names\n","class_names[:10]"],"metadata":{"id":"TvdC-M9_7AHF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Exploring the Food101 data from TensorFlow Datasets\n","\n","Now we've downloaded the Food101 dataset from TensorFlow Datasets, how about we do what any good data explorer should?\n","\n","In other words, \"visualize, visualize, visualize\".\n","\n","Let's find out a few details about our dataset:\n","\n","- The shape of our input data (image tensors)\n","- The datatype of our input data\n","- What the labels of our input data look like (e.g. one-hot encoded versus label-encoded)\n","- Do the labels match up with the class names?\n","\n","To do this, let's take one sample off the training data (using the [`.take()` method](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#take)) and explore it."],"metadata":{"id":"kHxrvV6q7K3s"}},{"cell_type":"code","source":["# Take on sample from the training data\n","train_one_sample = train_data.take(1) # samples are in (image_tensor, label) format"],"metadata":{"id":"nPGX4MxR7cuZ"},"execution_count":null,"outputs":[]}]}