{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP/w+Ylc2bgbZ/5dEWUxMFL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["04. Transfer Learning with TensorFlow Part 1: Feature Extraction\n","\n","We've built a bunch of convolutional neural networks from scratch and they all seem to be learning, however, there is still plenty of room for improvement.\n","\n","To improve our model(s), we could spend a while trying different configurations, adding more layers, changing the learning rate, adjusting the number of neurons per layer, and more.\n","\n","However, doing this is very time-consuming.\n","\n","Luckily, there's a technique we can use to save time.\n","\n","It's called **transfer learning**, in other words, taking the patterns (also called weights) another model has learned from another problem and using them for our problem.\n","\n","There are two main benefits to using transfer learning:\n","\n","1. Can leverage an existing neural network architecture proven to work on problems similar to our own.\n","2. Can leverage a working neural network architecture that has **already learned** patterns on similar data to our own. This often results in achieving great results with less custom data.\n","\n","What this means is, that instead of hand-crafting our neural network architectures or building them from scratch, we can utilize models that have worked for others.\n","\n","And instead of training our models from scratch on our datasets, we can take the patterns a model has learned from datasets such as [ImageNet](http://www.image-net.org/) (millions of images of different objects) and use them as the foundation of our own. Doing this often leads to getting great results with less data.\n","\n","Over the next few notebooks, we'll see the power of transfer learning in action."],"metadata":{"id":"4kh1770owib2"}},{"cell_type":"markdown","source":["## What we're going to cover\n","\n","We're going to go through the following with TensorFlow:\n","\n","- Introduce transfer learning (a way to beat all of our old self-built models)\n","- Using a smaller dataset to experiment faster (10% of training samples of 10 classes of food)\n","- Build a transfer learning feature extraction model using TensorFlow Hub\n","- Introduce the TensorBoard callback to track model training results\n","- Compare model results using TensorBoard"],"metadata":{"id":"kJOQKxB5xSTw"}},{"cell_type":"markdown","source":["## How you can use this notebook\n","\n","You can read through the descriptions and the code (it should all run, except for the cells that error on purpose), but there's a better option.\n","\n","Write all of the code yourself.\n","\n","Yes. I'm serious. Create a new notebook, and rewrite each line by yourself. Investigate it, see if you can break it, and why it breaks.\n","\n","You don't have to write the text descriptions but writing the code yourself is a great way to get hands-on experience.\n","\n","Don't worry if you make mistakes, we all do. The way to get better and make less mistakes is to **write more code**."],"metadata":{"id":"MjYVaUT3xdCr"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2iSwcSOywgIN","executionInfo":{"status":"ok","timestamp":1700132207673,"user_tz":-540,"elapsed":13,"user":{"displayName":"Hee Seong Yang","userId":"11765788859671095501"}},"outputId":"69d982d9-8ccc-4af5-a669-2711c2c2203d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Notebook last run (end-to-end): 2023-11-16 10:56:47.645684\n"]}],"source":["# Add timestamp\n","import datetime\n","print(f\"Notebook last run (end-to-end): {datetime.datetime.now()}\")"]},{"cell_type":"markdown","source":["## Using a GPU\n","\n","To begin, let's check to see if we're using a GPU. Using a GPU will make sure our model trains faster than using just a CPU."],"metadata":{"id":"bKXOl_yZxqlG"}},{"cell_type":"code","source":["# Are we using a GPU?\n","!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z5A3pIpfxpaE","executionInfo":{"status":"ok","timestamp":1700132224798,"user_tz":-540,"elapsed":590,"user":{"displayName":"Hee Seong Yang","userId":"11765788859671095501"}},"outputId":"67c2214c-c48c-462e-d09c-1f7b4d0e95ec"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/bin/bash: line 1: nvidia-smi: command not found\n"]}]},{"cell_type":"markdown","source":["If the cell above doesn't output something which looks like:\n","\n","```\n","Fri Sep  4 03:35:21 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 450.66       Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   35C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n","```\n","Go to Runtime -> Change Runtime Type -> Hardware Accelerator and select \"GPU\", then rerun the cell above."],"metadata":{"id":"Bd9YGGChxxf9"}},{"cell_type":"markdown","source":["## Transfer learning with TensorFlow Hub: Getting great results with 10% of the data\n","\n","If you've been thinking, \"Surely someone else has spent the time crafting the right model for the job...\" then you're in luck.\n","\n","For many of the problems you'll want to use deep learning for, chances are, a working model already exists.\n","\n","And the good news is, you can access many of them on TensorFlow Hub.\n","\n","[TensorFlow Hub](https://tfhub.dev/) is a repository for existing model components. It makes it so you can import and use a fully trained model with as little as a URL.\n","\n","Now, I want to demonstrate the power of transfer learning to you.\n","\n","To do so, what if I told you we could get much of the same results (or better) than our best model has gotten so far with only 10% of the original data, in other words, 10x fewer data?\n","\n","This seems counterintuitive right?\n","\n","Wouldn't you think more examples of what a picture of food looked like led to better results?\n","\n","And you'd be right if you thought so, generally, more data leads to better results.\n","\n","However, what if you didn't have more data? What if instead of 750 images per class, you had 75 images per class?\n","\n","Collecting 675 more images of a certain class could take a long time.\n","\n","So this is where another major benefit of transfer learning comes in.\n","\n","**Transfer learning often allows you to get great results with less data.**\n","\n","But don't just take my word for it. Let's download a subset of the data we've been using, namely 10% of the training data from the `10_food_classes` dataset and use it to train a food image classifier.\n","\n","![image0](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/04-transfer-learning-feature-extraction.png)\n","*What we're working towards building. Taking a pre-trained model and adding our custom layers on top, extracting all of the underlying patterns learned on another dataset from our images.*"],"metadata":{"id":"r66i5QBxx9jL"}},{"cell_type":"markdown","source":["## Downloading and becoming one with the data"],"metadata":{"id":"QFqeR3LNXMKC"}},{"cell_type":"code","source":["# Get data (10% of labels)\n","import zipfile\n","\n","# Download data\n","!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n","\n","# Unzip the downloaded file\n","zip_ref = zipfile.ZipFile(\"10_food_classes_10_percent.zip\", \"r\")\n","zip_ref.extractall()\n","zip_ref.close()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZUjVRTHvxvnV","executionInfo":{"status":"ok","timestamp":1700142067987,"user_tz":-540,"elapsed":3797,"user":{"displayName":"Hee Seong Yang","userId":"11765788859671095501"}},"outputId":"8f70f576-3516-46df-9a66-26f13f76da84"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-11-16 13:41:04--  https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n","Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.216.207, 173.194.217.207, 173.194.218.207, ...\n","Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.216.207|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 168546183 (161M) [application/zip]\n","Saving to: ‘10_food_classes_10_percent.zip’\n","\n","10_food_classes_10_ 100%[===================>] 160.74M   102MB/s    in 1.6s    \n","\n","2023-11-16 13:41:06 (102 MB/s) - ‘10_food_classes_10_percent.zip’ saved [168546183/168546183]\n","\n"]}]},{"cell_type":"code","source":["# How many images are in each folder?\n","import os\n","\n","# Walk through 10 percent data directory and list number of files\n","for dirpath, dirnames, filenames in os.walk('10_food_classes_10_percent'):\n","    print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w7xNrL9lXR_8","executionInfo":{"status":"ok","timestamp":1700142179357,"user_tz":-540,"elapsed":504,"user":{"displayName":"Hee Seong Yang","userId":"11765788859671095501"}},"outputId":"84937dde-7343-4cc8-c51c-ccf36339c49c"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["There are 2 directories and 0 images in '10_food_classes_10_percent'.\n","There are 10 directories and 0 images in '10_food_classes_10_percent/train'.\n","There are 0 directories and 75 images in '10_food_classes_10_percent/train/steak'.\n","There are 0 directories and 75 images in '10_food_classes_10_percent/train/fried_rice'.\n","There are 0 directories and 75 images in '10_food_classes_10_percent/train/sushi'.\n","There are 0 directories and 75 images in '10_food_classes_10_percent/train/pizza'.\n","There are 0 directories and 75 images in '10_food_classes_10_percent/train/hamburger'.\n","There are 0 directories and 75 images in '10_food_classes_10_percent/train/ice_cream'.\n","There are 0 directories and 75 images in '10_food_classes_10_percent/train/ramen'.\n","There are 0 directories and 75 images in '10_food_classes_10_percent/train/chicken_wings'.\n","There are 0 directories and 75 images in '10_food_classes_10_percent/train/grilled_salmon'.\n","There are 0 directories and 75 images in '10_food_classes_10_percent/train/chicken_curry'.\n","There are 10 directories and 0 images in '10_food_classes_10_percent/test'.\n","There are 0 directories and 250 images in '10_food_classes_10_percent/test/steak'.\n","There are 0 directories and 250 images in '10_food_classes_10_percent/test/fried_rice'.\n","There are 0 directories and 250 images in '10_food_classes_10_percent/test/sushi'.\n","There are 0 directories and 250 images in '10_food_classes_10_percent/test/pizza'.\n","There are 0 directories and 250 images in '10_food_classes_10_percent/test/hamburger'.\n","There are 0 directories and 250 images in '10_food_classes_10_percent/test/ice_cream'.\n","There are 0 directories and 250 images in '10_food_classes_10_percent/test/ramen'.\n","There are 0 directories and 250 images in '10_food_classes_10_percent/test/chicken_wings'.\n","There are 0 directories and 250 images in '10_food_classes_10_percent/test/grilled_salmon'.\n","There are 0 directories and 250 images in '10_food_classes_10_percent/test/chicken_curry'.\n"]}]},{"cell_type":"markdown","source":["Notice how each of the training directories now has 75 images rather than 750 images. This is key to demonstrating how well transfer learning can perform with fewer labeled images.\n","\n","The test directories still have the same amount of images. This means we'll be training on less data but evaluating our models on the same amount of test data."],"metadata":{"id":"rCzhWvNwXynX"}},{"cell_type":"markdown","source":["## Creating data loaders (preparing the data)\n","\n","Now we've downloaded the data, let's use the [`ImageDataGenerator`](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator) class along with the `flow_from_directory` method to load in our images."],"metadata":{"id":"0Wp0bn6aX5XM"}},{"cell_type":"code","source":["# Set up data inputs\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","IMAGE_SHAPE = (224, 224)\n","BATCH_SIZE = 32\n","\n","train_dir = \"10_food_classes_10_percent/train/\"\n","test_dir = \"10_food_classes_10_percent/test/\"\n","\n","train_datagen = ImageDataGenerator(rescale = 1 / 255)\n","test_datagen = ImageDataGenerator(rescale = 1 / 255)\n","\n","print(\"Training images:\")\n","train_data_10_percent = train_datagen.flow_from_directory(train_dir,\n","                                                          target_size=IMAGE_SHAPE,\n","                                                          batch_size=BATCH_SIZE,\n","                                                          class_mode='categorical')\n","\n","print(\"Testing images:\")\n","test_data_10_percent = test_datagen.flow_from_directory(test_dir,\n","                                                        target_size=IMAGE_SHAPE,\n","                                                        batch_size=BATCH_SIZE,\n","                                                        class_mode='categorical')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t77N3-HJXt-f","executionInfo":{"status":"ok","timestamp":1700142441850,"user_tz":-540,"elapsed":430,"user":{"displayName":"Hee Seong Yang","userId":"11765788859671095501"}},"outputId":"a70c7b46-3ab7-4237-9608-da4a930d3e9e"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Training images:\n","Found 750 images belonging to 10 classes.\n","Testing images:\n","Found 2500 images belonging to 10 classes.\n"]}]},{"cell_type":"markdown","source":["Excellent! Loading in the data we can see we've got 750 images in the training dataset belonging to 10 classes (75 per class) and 2500 images in the test set belonging to 10 classes (250 per class)."],"metadata":{"id":"n8M31BEAYxOI"}},{"cell_type":"markdown","source":["## Setting up callbacks (things to run whilst our model trains)\n","\n","Before we build a model, there's an important concept we're going to get familiar with because it's going to play a key role in our future model-building experiments.\n","\n","And that concept is **callbacks**.\n","\n","[Callbacks](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks) are extra functionality you can add to your models to be performed during or after training. Some of the most popular callbacks include:\n","\n","- [**Experiment tracking with TensorBoard**](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/TensorBoard) - log the performance of multiple models and then view and compare these models in a visual way on [TensorBoard](https://www.tensorflow.org/tensorboard) (a dashboard for inspecting neural network parameters). Helpful to compare the results of different models on your data.\n","- [**Model checkpointing**](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint) - save your model as it trains so you can stop training if needed and come back to continue where you left. Helpful if training takes a long time and can't be done in one sitting.\n","- [**Early stopping**](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping) - leave your model training for an arbitrary amount of time and have it stop training automatically when it ceases to improve. Helpful when you've got a large dataset and don't know how long training will take.\n","\n","We'll explore each of these over time but for this notebook, we'll see how the TensorBoard callback can be used.\n","\n","The TensorBoard callback can be accessed using [`tf.keras.callbacks.TensorBoard()`](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/TensorBoard).\n","\n","Its main functionality is saving a model's training performance metrics to a specified `log_dir`.\n","\n","By default, logs are recorded every epoch using the `update_freq='epoch'` parameter. This is a good default since tracking model performance often can slow down the model training.\n","\n","To track our modeling experiments using TensorBoard, let's create a function that creates a TensorBoard callback for us.\n","\n","> 🔑 Note: We create a function for creating a TensorBoard callback because as we'll see later on, each model needs its TensorBoard callback instance (so the function will create a new one each time it runs)."],"metadata":{"id":"SZr_4XUDY3dr"}},{"cell_type":"code","source":["# Create tensorboard callback (functionized because need to create a new one for each model)\n","import datetime\n","\n","def create_tensorboard_callback(dir_name, experiment_name):\n","    log_dir = dir_name + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n","    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir = log_dir)\n","    print(f\"Saving TensorBoard log files to: {log_dir}\")\n","    return tensorboard_callback"],"metadata":{"id":"-0_6_cy7YuFo","executionInfo":{"status":"ok","timestamp":1700143031056,"user_tz":-540,"elapsed":373,"user":{"displayName":"Hee Seong Yang","userId":"11765788859671095501"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["Because you're likely to run multiple experiments, it's a good idea to be able to track them in some way.\n","\n","In our case, our function saves a model's performance logs to a directory named `[dir_name]/[experiment_name]/[current_timestamp]`, where:\n","\n","- `dir_name` is the overall logs directory\n","- `experiment_name` is the particular experiment\n","- `current_timestamp` is the time the experiment started based on Python's [`datetime.datetime().now()`](https://docs.python.org/3/library/datetime.html#datetime.datetime.now)\n","\n","> 🔑 Note: Depending on your use case, the above experimenting tracking naming method may work or you might require something more specific. The good news is, the TensorBoard callback makes it easy to track modeling logs as long as you specify where to track them. So you can get as creative as you like with how you name your experiments, just make sure you or your team can understand them."],"metadata":{"id":"_bV58wNRa_3N"}},{"cell_type":"markdown","source":["## Creating models using TensorFlow Hub"],"metadata":{"id":"pSkByRuxbdgP"}},{"cell_type":"code","source":[],"metadata":{"id":"E-tVAw8Na97Y"},"execution_count":null,"outputs":[]}]}