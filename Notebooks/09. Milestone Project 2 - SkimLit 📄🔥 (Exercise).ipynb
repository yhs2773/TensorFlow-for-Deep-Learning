{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyO4cyAZ7QWhYBgXZx/vZ63X"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# 🛠 Exercises"],"metadata":{"id":"mgsTbBjWJ5S3"}},{"cell_type":"markdown","source":["## 0. Prerequisites"],"metadata":{"id":"wy8Tx-D9KclZ"}},{"cell_type":"code","source":["# import libraries\n","import os\n","import random\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import tensorflow_hub as hub"],"metadata":{"id":"ZJr0iy9uKQEb","executionInfo":{"status":"ok","timestamp":1704371305079,"user_tz":-540,"elapsed":5633,"user":{"displayName":"Heeseong Yang","userId":"11765788859671095501"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["# get helper functions\n","!wget https://raw.githubusercontent.com/yhs2773/TensorFlow-for-Deep-Learning/main/helper_functions.py\n","from helper_functions import calculate_results"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DPKr63fEWYpz","executionInfo":{"status":"ok","timestamp":1704371306059,"user_tz":-540,"elapsed":986,"user":{"displayName":"Heeseong Yang","userId":"11765788859671095501"}},"outputId":"66f6a2db-5978-48a3-fd62-d8d3783612f4"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-01-04 12:28:23--  https://raw.githubusercontent.com/yhs2773/TensorFlow-for-Deep-Learning/main/helper_functions.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 11093 (11K) [text/plain]\n","Saving to: ‘helper_functions.py’\n","\n","\rhelper_functions.py   0%[                    ]       0  --.-KB/s               \rhelper_functions.py 100%[===================>]  10.83K  --.-KB/s    in 0s      \n","\n","2024-01-04 12:28:23 (78.5 MB/s) - ‘helper_functions.py’ saved [11093/11093]\n","\n"]}]},{"cell_type":"code","source":["# get data\n","!git clone https://github.com/Franck-Dernoncourt/pubmed-rct.git\n","!ls pubmed-rct"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3L-dVp5LH1qu","executionInfo":{"status":"ok","timestamp":1704371318950,"user_tz":-540,"elapsed":12894,"user":{"displayName":"Heeseong Yang","userId":"11765788859671095501"}},"outputId":"33bc7469-9339-4193-8ea6-c3a4c36cb498"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'pubmed-rct'...\n","remote: Enumerating objects: 39, done.\u001b[K\n","remote: Counting objects: 100% (14/14), done.\u001b[K\n","remote: Compressing objects: 100% (9/9), done.\u001b[K\n","remote: Total 39 (delta 8), reused 5 (delta 5), pack-reused 25\u001b[K\n","Receiving objects: 100% (39/39), 177.08 MiB | 20.01 MiB/s, done.\n","Resolving deltas: 100% (15/15), done.\n","Updating files: 100% (13/13), done.\n","PubMed_200k_RCT\t\t\t\t       PubMed_20k_RCT_numbers_replaced_with_at_sign\n","PubMed_200k_RCT_numbers_replaced_with_at_sign  README.md\n","PubMed_20k_RCT\n"]}]},{"cell_type":"code","source":["# set directory for the 20k dataset\n","data_dir = \"pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/\""],"metadata":{"id":"f0Fqdl5mICP9","executionInfo":{"status":"ok","timestamp":1704371318951,"user_tz":-540,"elapsed":12,"user":{"displayName":"Heeseong Yang","userId":"11765788859671095501"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# list of target directories\n","filenames = [data_dir + filename for filename in os.listdir(data_dir)]\n","filenames"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Uz9BXinfIHik","executionInfo":{"status":"ok","timestamp":1704371318951,"user_tz":-540,"elapsed":11,"user":{"displayName":"Heeseong Yang","userId":"11765788859671095501"}},"outputId":"563a9cce-7e74-4404-e736-f796e239f8e0"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/test.txt',\n"," 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/dev.txt',\n"," 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/train.txt']"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["# function to read lines of a document\n","def get_lines(filename):\n","    with open(filename, \"r\") as f:\n","        return f.readlines()"],"metadata":{"id":"yYQphXoTIYe-","executionInfo":{"status":"ok","timestamp":1704371318951,"user_tz":-540,"elapsed":9,"user":{"displayName":"Heeseong Yang","userId":"11765788859671095501"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["train_lines = get_lines(data_dir + \"train.txt\")\n","train_lines[:20]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7GT3Ly7-InxE","executionInfo":{"status":"ok","timestamp":1704371318951,"user_tz":-540,"elapsed":8,"user":{"displayName":"Heeseong Yang","userId":"11765788859671095501"}},"outputId":"5f85f3d6-0687-4a9e-dd75-0d9a9b9ca1d2"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['###24293578\\n',\n"," 'OBJECTIVE\\tTo investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .\\n',\n"," 'METHODS\\tA total of @ patients with primary knee OA were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .\\n',\n"," 'METHODS\\tOutcome measures included pain reduction and improvement in function scores and systemic inflammation markers .\\n',\n"," 'METHODS\\tPain was assessed using the visual analog pain scale ( @-@ mm ) .\\n',\n"," 'METHODS\\tSecondary outcome measures included the Western Ontario and McMaster Universities Osteoarthritis Index scores , patient global assessment ( PGA ) of the severity of knee OA , and @-min walk distance ( @MWD ) .\\n',\n"," 'METHODS\\tSerum levels of interleukin @ ( IL-@ ) , IL-@ , tumor necrosis factor ( TNF ) - , and high-sensitivity C-reactive protein ( hsCRP ) were measured .\\n',\n"," 'RESULTS\\tThere was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , PGA , and @MWD at @ weeks .\\n',\n"," 'RESULTS\\tThe mean difference between treatment arms ( @ % CI ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .\\n',\n"," 'RESULTS\\tFurther , there was a clinically relevant reduction in the serum levels of IL-@ , IL-@ , TNF - , and hsCRP at @ weeks in the intervention group when compared to the placebo group .\\n',\n"," 'RESULTS\\tThese differences remained significant at @ weeks .\\n',\n"," 'RESULTS\\tThe Outcome Measures in Rheumatology Clinical Trials-Osteoarthritis Research Society International responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .\\n',\n"," 'CONCLUSIONS\\tLow-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee OA ( ClinicalTrials.gov identifier NCT@ ) .\\n',\n"," '\\n',\n"," '###24854809\\n',\n"," 'BACKGROUND\\tEmotional eating is associated with overeating and the development of obesity .\\n',\n"," 'BACKGROUND\\tYet , empirical evidence for individual ( trait ) differences in emotional eating and cognitive mechanisms that contribute to eating during sad mood remain equivocal .\\n',\n"," 'OBJECTIVE\\tThe aim of this study was to test if attention bias for food moderates the effect of self-reported emotional eating during sad mood ( vs neutral mood ) on actual food intake .\\n',\n"," 'OBJECTIVE\\tIt was expected that emotional eating is predictive of elevated attention for food and higher food intake after an experimentally induced sad mood and that attentional maintenance on food predicts food intake during a sad versus a neutral mood .\\n',\n"," 'METHODS\\tParticipants ( N = @ ) were randomly assigned to one of the two experimental mood induction conditions ( sad/neutral ) .\\n']"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["# function to preprocess data\n","def preprocess_text_with_line_numbers(filename):\n","    input_lines = get_lines(filename)\n","    abstract_lines = \"\"\n","    abstract_samples = []\n","\n","    for line in input_lines:\n","        if line.startswith(\"###\"):\n","            abstract_id = line\n","            abstract_lines = \"\"\n","        elif line.isspace():\n","            abstract_line_split = abstract_lines.splitlines()\n","\n","            for abstract_line_number, abstract_line in enumerate(abstract_line_split):\n","                line_data = {}\n","                target_text_split = abstract_line.split(\"\\t\")\n","                line_data['target'] = target_text_split[0]\n","                line_data['text'] = target_text_split[1].lower()\n","                line_data['line_number'] = abstract_line_number\n","                line_data['total_lines'] = len(abstract_line_split) - 1\n","                abstract_samples.append(line_data)\n","        else:\n","            abstract_lines += line\n","\n","    return abstract_samples"],"metadata":{"id":"NTxBjoqKIxGo","executionInfo":{"status":"ok","timestamp":1704371318951,"user_tz":-540,"elapsed":6,"user":{"displayName":"Heeseong Yang","userId":"11765788859671095501"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# preprocess data\n","train_samples = preprocess_text_with_line_numbers(data_dir + \"train.txt\")\n","val_samples = preprocess_text_with_line_numbers(data_dir + \"dev.txt\")\n","test_samples = preprocess_text_with_line_numbers(data_dir + \"test.txt\")"],"metadata":{"id":"fkbwS4M8KF2m","executionInfo":{"status":"ok","timestamp":1704371319941,"user_tz":-540,"elapsed":995,"user":{"displayName":"Heeseong Yang","userId":"11765788859671095501"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# turn into data frames\n","train_df = pd.DataFrame(train_samples)\n","val_df = pd.DataFrame(val_samples)\n","test_df = pd.DataFrame(test_samples)"],"metadata":{"id":"Tjoju2KPKQEc","executionInfo":{"status":"ok","timestamp":1704371320826,"user_tz":-540,"elapsed":888,"user":{"displayName":"Heeseong Yang","userId":"11765788859671095501"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# get lists of sentences\n","train_sentences = train_df['text'].tolist()\n","val_sentences = val_df['text'].tolist()\n","test_sentences = test_df['text'].tolist()"],"metadata":{"id":"L0aI3QbIKfAd","executionInfo":{"status":"ok","timestamp":1704371320827,"user_tz":-540,"elapsed":4,"user":{"displayName":"Heeseong Yang","userId":"11765788859671095501"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# one-hot encode labels\n","from sklearn.preprocessing import OneHotEncoder\n","ohe = OneHotEncoder(sparse_output=False)\n","train_oh = ohe.fit_transform(train_df['target'].to_numpy().reshape(-1, 1))\n","val_oh = ohe.transform(val_df['target'].to_numpy().reshape(-1, 1))\n","test_oh = ohe.transform(test_df['target'].to_numpy().reshape(-1, 1))"],"metadata":{"id":"xFwe3Q8sKuM9","executionInfo":{"status":"ok","timestamp":1704371320827,"user_tz":-540,"elapsed":4,"user":{"displayName":"Heeseong Yang","userId":"11765788859671095501"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# label encode labels (instrumental in getting class names)\n","from sklearn.preprocessing import LabelEncoder\n","le = LabelEncoder()\n","train_le = le.fit_transform(train_df['target'].to_numpy())\n","val_le = le.transform(val_df['target'].to_numpy())\n","test_le = le.transform(test_df['target'].to_numpy())"],"metadata":{"id":"c1W3vwqZLLKc","executionInfo":{"status":"ok","timestamp":1704371321176,"user_tz":-540,"elapsed":353,"user":{"displayName":"Heeseong Yang","userId":"11765788859671095501"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# get num_classes and class_names\n","num_classes = len(le.classes_)\n","class_names = le.classes_\n","num_classes, class_names"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nd2dvg9kLgc9","executionInfo":{"status":"ok","timestamp":1704371321176,"user_tz":-540,"elapsed":3,"user":{"displayName":"Heeseong Yang","userId":"11765788859671095501"}},"outputId":"fb880973-d54c-4b6c-a567-0cb3536ab519"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(5,\n"," array(['BACKGROUND', 'CONCLUSIONS', 'METHODS', 'OBJECTIVE', 'RESULTS'],\n","       dtype=object))"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["# download pre-trained USE\n","tf_hub_embedding_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n","                                        trainable=False,\n","                                        name='universal_sentence_encoder')"],"metadata":{"id":"yKz_gXbpLno2","executionInfo":{"status":"ok","timestamp":1704371349771,"user_tz":-540,"elapsed":28597,"user":{"displayName":"Heeseong Yang","userId":"11765788859671095501"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# function to split sentences into characters\n","def split_chars(text):\n","    return \" \".join(list(text))"],"metadata":{"id":"ruF2QGFpR7Pj","executionInfo":{"status":"ok","timestamp":1704371349772,"user_tz":-540,"elapsed":5,"user":{"displayName":"Heeseong Yang","userId":"11765788859671095501"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["# split sentence into characters\n","train_chars = [split_chars(sentence) for sentence in train_sentences]\n","val_chars = [split_chars(sentence) for sentence in val_sentences]\n","test_chars = [split_chars(sentence) for sentence in test_sentences]\n","\n","# check the distribution of character length\n","char_lens = [len(sentence) for sentence in train_sentences]\n","output_seq_char_len = int(np.percentile(char_lens, 95))\n","output_seq_char_len"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iYAL79M9SFiP","executionInfo":{"status":"ok","timestamp":1704371351440,"user_tz":-540,"elapsed":1672,"user":{"displayName":"Heeseong Yang","userId":"11765788859671095501"}},"outputId":"bc76e869-7f29-4b11-954f-1a37a17d9006"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["290"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["import string\n","\n","alphabet = string.ascii_lowercase\n","alphabet"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"5g4vz5LtW3Xh","executionInfo":{"status":"ok","timestamp":1704371351441,"user_tz":-540,"elapsed":6,"user":{"displayName":"Heeseong Yang","userId":"11765788859671095501"}},"outputId":"277677d0-7409-426d-c61e-af2fb5b27000"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'abcdefghijklmnopqrstuvwxyz'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["# create char-level token vectorizer\n","char_vectorizer = tf.keras.layers.TextVectorization(max_tokens=len(alphabet) + 2,\n","                                                    output_sequence_length=output_seq_char_len,\n","                                                    name='char_vectorizer')\n","\n","# adap character vectorizer\n","char_vectorizer.adapt(train_chars)"],"metadata":{"id":"vwy8fPzzXIAm","executionInfo":{"status":"ok","timestamp":1704371372479,"user_tz":-540,"elapsed":21043,"user":{"displayName":"Heeseong Yang","userId":"11765788859671095501"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["# get char vocab\n","char_vocab = char_vectorizer.get_vocabulary()"],"metadata":{"id":"PK9LvBG2Xvfo","executionInfo":{"status":"ok","timestamp":1704371372480,"user_tz":-540,"elapsed":17,"user":{"displayName":"Heeseong Yang","userId":"11765788859671095501"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["# char embedding layer\n","char_embed = tf.keras.layers.Embedding(input_dim=len(alphabet) + 2,\n","                                       output_dim=25,\n","                                       name='char_embed')"],"metadata":{"id":"1etLv564X-TY","executionInfo":{"status":"ok","timestamp":1704371372480,"user_tz":-540,"elapsed":16,"user":{"displayName":"Heeseong Yang","userId":"11765788859671095501"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["# check the distribution of line_number\n","int(np.percentile(train_df.line_number, 98))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Icc8gJzV2WDg","executionInfo":{"status":"ok","timestamp":1704371372480,"user_tz":-540,"elapsed":16,"user":{"displayName":"Heeseong Yang","userId":"11765788859671095501"}},"outputId":"c41c7862-d535-4213-e6cf-5a2820a1a010"},"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["15"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["# create line_number one-hot\n","train_line_numbers_oh = tf.one_hot(train_df['line_number'].to_numpy(), depth=15)\n","val_line_numbers_oh = tf.one_hot(val_df[\"line_number\"].to_numpy(), depth=15)\n","test_line_numbers_oh = tf.one_hot(test_df[\"line_number\"].to_numpy(), depth=15)"],"metadata":{"id":"4B4OSPfwYY_e","executionInfo":{"status":"ok","timestamp":1704371372480,"user_tz":-540,"elapsed":15,"user":{"displayName":"Heeseong Yang","userId":"11765788859671095501"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["# check the distribution of total_lines\n","np.percentile(train_df.total_lines, 98)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YvZyJx0y3I24","executionInfo":{"status":"ok","timestamp":1704371372480,"user_tz":-540,"elapsed":14,"user":{"displayName":"Heeseong Yang","userId":"11765788859671095501"}},"outputId":"2df49119-ff30-4762-f52e-7704c8555536"},"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["20.0"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["# create total_lines one-hot\n","train_total_lines_oh = tf.one_hot(train_df['total_lines'].to_numpy(), depth=20)\n","val_total_lines_oh = tf.one_hot(val_df[\"total_lines\"].to_numpy(), depth=20)\n","test_total_lines_oh = tf.one_hot(test_df[\"total_lines\"].to_numpy(), depth=20)"],"metadata":{"id":"Qri0WaQf3P_V","executionInfo":{"status":"ok","timestamp":1704371372480,"user_tz":-540,"elapsed":12,"user":{"displayName":"Heeseong Yang","userId":"11765788859671095501"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["# datasets\n","# train dataset\n","train_features = tf.data.Dataset.from_tensor_slices((train_line_numbers_oh,\n","                                                     train_total_lines_oh,\n","                                                     train_sentences,\n","                                                     train_chars))\n","train_labels = tf.data.Dataset.from_tensor_slices(train_oh)\n","train_ds = tf.data.Dataset.zip((train_features, train_labels))\n","train_ds = train_ds.batch(32).prefetch(tf.data.AUTOTUNE)\n","\n","# validation dataset\n","val_features = tf.data.Dataset.from_tensor_slices((val_line_numbers_oh,\n","                                                   val_total_lines_oh,\n","                                                   val_sentences,\n","                                                   val_chars))\n","val_labels = tf.data.Dataset.from_tensor_slices(val_oh)\n","val_ds = tf.data.Dataset.zip((val_features, val_labels))\n","val_ds = val_ds.batch(32).prefetch(tf.data.AUTOTUNE)"],"metadata":{"id":"IJbMUdx5aQs8","executionInfo":{"status":"ok","timestamp":1704371376417,"user_tz":-540,"elapsed":1824,"user":{"displayName":"Heeseong Yang","userId":"11765788859671095501"}}},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":["## 1. Train `model_5` on all of the data in the training dataset for as many epochs until it stops improving. Since this might take a while, you might want to use:\n","- [`tf.keras.callbacks.ModelCheckpoint`](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint) to save the model's best weights only.\n","- [`tf.keras.callbacks.EarlyStopping`](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping) to stop the model from training once the validation loss has stopped improving for ~3 epochs."],"metadata":{"id":"C8dhw7ddJ9GM"}},{"cell_type":"code","source":["# replicate model_5\n","# token input model\n","token_inputs = tf.keras.layers.Input(shape=[], dtype=tf.string)\n","token_embeddings = tf_hub_embedding_layer(token_inputs)\n","token_outputs = tf.keras.layers.Dense(128, activation='relu')(token_embeddings)\n","token_model = tf.keras.Model(inputs=token_inputs, outputs=token_outputs)\n","\n","# char input model\n","char_inputs = tf.keras.layers.Input(shape=(1,), dtype=tf.string)\n","char_vectors = char_vectorizer(char_inputs)\n","char_embeddings = char_embed(char_vectors)\n","char_bi_lstm = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32))(char_embeddings)\n","char_model = tf.keras.Model(inputs=char_inputs, outputs=char_bi_lstm)\n","\n","# line numbers model\n","line_number_inputs = tf.keras.layers.Input(shape=(15,), dtype=tf.int32)\n","x = tf.keras.layers.Dense(32, activation='relu')(line_number_inputs)\n","line_number_model = tf.keras.Model(inputs=line_number_inputs, outputs=x)\n","\n","# total lines model\n","total_lines_inputs = tf.keras.layers.Input(shape=(20,), dtype=tf.int32)\n","y = tf.keras.layers.Dense(32, activation='relu')(total_lines_inputs)\n","total_lines_model = tf.keras.Model(inputs=total_lines_inputs, outputs=y)\n","\n","# token and char hybrid embedding\n","combined_embeddings = tf.keras.layers.Concatenate()([token_model.output, char_model.output])\n","z = tf.keras.layers.Dense(256, activation='relu')(combined_embeddings)\n","z = tf.keras.layers.Dropout(0.5)(z)\n","\n","# concat combined embedding with line number and total lines models\n","z = tf.keras.layers.Concatenate()([line_number_model.output, total_lines_model.output, z])\n","\n","# output layer\n","output_layer = tf.keras.layers.Dense(num_classes, activation='softmax')(z)\n","\n","# model_5\n","model_5 = tf.keras.Model(inputs=[line_number_model.input,\n","                                 total_lines_model.input,\n","                                 token_model.input,\n","                                 char_model.input],\n","                         outputs=output_layer)"],"metadata":{"id":"h3Pav2-dKaPd","executionInfo":{"status":"ok","timestamp":1704371374598,"user_tz":-540,"elapsed":2130,"user":{"displayName":"Heeseong Yang","userId":"11765788859671095501"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["# model summary\n","model_5.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kuRNSOLK3tVJ","executionInfo":{"status":"ok","timestamp":1704371374598,"user_tz":-540,"elapsed":14,"user":{"displayName":"Heeseong Yang","userId":"11765788859671095501"}},"outputId":"e371c753-062f-4757-b618-03bbf32c299e"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_4\"\n","__________________________________________________________________________________________________\n"," Layer (type)                Output Shape                 Param #   Connected to                  \n","==================================================================================================\n"," input_2 (InputLayer)        [(None, 1)]                  0         []                            \n","                                                                                                  \n"," input_1 (InputLayer)        [(None,)]                    0         []                            \n","                                                                                                  \n"," char_vectorizer (TextVecto  (None, 290)                  0         ['input_2[0][0]']             \n"," rization)                                                                                        \n","                                                                                                  \n"," universal_sentence_encoder  (None, 512)                  2567978   ['input_1[0][0]']             \n","  (KerasLayer)                                            24                                      \n","                                                                                                  \n"," char_embed (Embedding)      (None, 290, 25)              700       ['char_vectorizer[0][0]']     \n","                                                                                                  \n"," dense (Dense)               (None, 128)                  65664     ['universal_sentence_encoder[0\n","                                                                    ][0]']                        \n","                                                                                                  \n"," bidirectional (Bidirection  (None, 64)                   14848     ['char_embed[0][0]']          \n"," al)                                                                                              \n","                                                                                                  \n"," concatenate (Concatenate)   (None, 192)                  0         ['dense[0][0]',               \n","                                                                     'bidirectional[0][0]']       \n","                                                                                                  \n"," input_3 (InputLayer)        [(None, 15)]                 0         []                            \n","                                                                                                  \n"," input_4 (InputLayer)        [(None, 20)]                 0         []                            \n","                                                                                                  \n"," dense_3 (Dense)             (None, 256)                  49408     ['concatenate[0][0]']         \n","                                                                                                  \n"," dense_1 (Dense)             (None, 32)                   512       ['input_3[0][0]']             \n","                                                                                                  \n"," dense_2 (Dense)             (None, 32)                   672       ['input_4[0][0]']             \n","                                                                                                  \n"," dropout (Dropout)           (None, 256)                  0         ['dense_3[0][0]']             \n","                                                                                                  \n"," concatenate_1 (Concatenate  (None, 320)                  0         ['dense_1[0][0]',             \n"," )                                                                   'dense_2[0][0]',             \n","                                                                     'dropout[0][0]']             \n","                                                                                                  \n"," dense_4 (Dense)             (None, 5)                    1605      ['concatenate_1[0][0]']       \n","                                                                                                  \n","==================================================================================================\n","Total params: 256931233 (980.11 MB)\n","Trainable params: 133409 (521.13 KB)\n","Non-trainable params: 256797824 (979.61 MB)\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"code","source":["# model callbacks\n","ckpt_path = 'model_5/model_5.ckpt'\n","mckpt = tf.keras.callbacks.ModelCheckpoint(filepath=ckpt_path,\n","                                           save_best_only=True,\n","                                           save_weights_only=True)\n","\n","es = tf.keras.callbacks.EarlyStopping(patience=3,\n","                                      restore_best_weights=True)"],"metadata":{"id":"S-iiQbM9YteZ","executionInfo":{"status":"ok","timestamp":1704371374598,"user_tz":-540,"elapsed":5,"user":{"displayName":"Heeseong Yang","userId":"11765788859671095501"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["# compile\n","model_5.compile(optimizer='adam',\n","                loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.2),\n","                metrics=['accuracy'])"],"metadata":{"id":"jO6oAGCQXxVF","executionInfo":{"status":"ok","timestamp":1704371374598,"user_tz":-540,"elapsed":5,"user":{"displayName":"Heeseong Yang","userId":"11765788859671095501"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["# train\n","history_5 = model_5.fit(train_ds,\n","                        epochs=500,\n","                        validation_data=val_ds,\n","                        validation_steps=int(len(val_ds) * 0.5),\n","                        callbacks=[mckpt, es])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zNYIhJnDbjiJ","outputId":"a4289738-9a18-48dc-acc8-8126d66cbcfe","executionInfo":{"status":"ok","timestamp":1704372749791,"user_tz":-540,"elapsed":1373378,"user":{"displayName":"Heeseong Yang","userId":"11765788859671095501"}}},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/500\n","5627/5627 [==============================] - 229s 36ms/step - loss: 0.9534 - accuracy: 0.8229 - val_loss: 0.9084 - val_accuracy: 0.8469\n","Epoch 2/500\n","5627/5627 [==============================] - 207s 37ms/step - loss: 0.9105 - accuracy: 0.8533 - val_loss: 0.8999 - val_accuracy: 0.8507\n","Epoch 3/500\n","5627/5627 [==============================] - 261s 46ms/step - loss: 0.8979 - accuracy: 0.8622 - val_loss: 0.8955 - val_accuracy: 0.8544\n","Epoch 4/500\n","5627/5627 [==============================] - 189s 34ms/step - loss: 0.8896 - accuracy: 0.8685 - val_loss: 0.8956 - val_accuracy: 0.8547\n","Epoch 5/500\n","5627/5627 [==============================] - 182s 32ms/step - loss: 0.8832 - accuracy: 0.8740 - val_loss: 0.8970 - val_accuracy: 0.8510\n","Epoch 6/500\n","5627/5627 [==============================] - 191s 34ms/step - loss: 0.8776 - accuracy: 0.8782 - val_loss: 0.8980 - val_accuracy: 0.8506\n"]}]},{"cell_type":"code","source":["# evaluate\n","model_5.evaluate(val_ds)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RuTch_Qk7alN","executionInfo":{"status":"ok","timestamp":1704372768945,"user_tz":-540,"elapsed":19170,"user":{"displayName":"Heeseong Yang","userId":"11765788859671095501"}},"outputId":"beadd3ca-2b82-4ba8-b11b-050ae39c8948"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["945/945 [==============================] - 19s 20ms/step - loss: 0.8967 - accuracy: 0.8559\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.8966736793518066, 0.8558520078659058]"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["# predict and calculate results\n","model_5_pred_probs = model_5.predict(val_ds)\n","model_5_preds = tf.argmax(model_5_pred_probs, axis=1)\n","results_5 = calculate_results(y_true=val_le, y_pred=model_5_preds)\n","results_5"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9o0mQuJF7tC9","executionInfo":{"status":"ok","timestamp":1704373092439,"user_tz":-540,"elapsed":20328,"user":{"displayName":"Heeseong Yang","userId":"11765788859671095501"}},"outputId":"8d151d8b-0ee7-4634-8d50-38913d260207"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["945/945 [==============================] - 20s 20ms/step\n"]},{"output_type":"execute_result","data":{"text/plain":["{'accuracy': 85.58519793459553,\n"," 'precision': 0.8575051236519442,\n"," 'recall': 0.8558519793459552,\n"," 'f1': 0.8527649681186131}"]},"metadata":{},"execution_count":34}]},{"cell_type":"markdown","source":["## 2. Check out the [Keras guide on using pre-trained GloVe embeddings](https://keras.io/examples/nlp/pretrained_word_embeddings/). Can you get this working with one of our models?\n","- Hint: You'll want to incorporate it with a custom token [Embedding](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding) layer.\n","- It's up to you whether or not you fine-tune the GloVe embeddings or leave them frozen."],"metadata":{"id":"tw2wEYXIKEgd"}},{"cell_type":"code","source":["# download and unzip pre-trained GloVe embeddings\n","!wget https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n","!unzip -q glove.6B.zip -d glove_embeddings"],"metadata":{"id":"1xNy3mz5KPhz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1704373359738,"user_tz":-540,"elapsed":198529,"user":{"displayName":"Heeseong Yang","userId":"11765788859671095501"}},"outputId":"c15a5e67-b8e0-47fd-ffb8-18a779734415"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-01-04 12:59:20--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n","Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n","Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 862182613 (822M) [application/zip]\n","Saving to: ‘glove.6B.zip’\n","\n","glove.6B.zip        100%[===================>] 822.24M  5.02MB/s    in 2m 40s  \n","\n","2024-01-04 13:02:00 (5.14 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n","\n"]}]},{"cell_type":"code","source":["# create text vectorizer\n","text_vectorizer = tf.keras.layers.TextVectorization(max_tokens=68000, output_sequence_length=55)\n","text_vectorizer.adapt(train_sentences)\n","rct_20k_text_vocab = text_vectorizer.get_vocabulary()                       # dictionary of integer to word\n","word_index = dict(zip(rct_20k_text_vocab, range(len(rct_20k_text_vocab))))  # dictionary of word to index"],"metadata":{"id":"IlgebP333dW2","executionInfo":{"status":"ok","timestamp":1704373383129,"user_tz":-540,"elapsed":23403,"user":{"displayName":"Heeseong Yang","userId":"11765788859671095501"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["# embedding dictionary\n","path_to_glove_file = \"glove_embeddings/glove.6B.100d.txt\"\n","\n","embeddings_index = {}\n","with open(path_to_glove_file) as f:\n","    for line in f:\n","        word, coefs = line.split(maxsplit=1)\n","        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n","        embeddings_index[word] = coefs\n","\n","print(f\"Found {len(embeddings_index)} word vectors.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FznddZok0k3z","executionInfo":{"status":"ok","timestamp":1704373390003,"user_tz":-540,"elapsed":6879,"user":{"displayName":"Heeseong Yang","userId":"11765788859671095501"}},"outputId":"9f99f3f0-092c-4382-f2f8-ab58e561d5f0"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 400000 word vectors.\n"]}]},{"cell_type":"code","source":["# prepare embedding matrix\n","num_tokens = len(rct_20k_text_vocab) + 2\n","embedding_dim = 100\n","hits = 0\n","misses = 0\n","\n","embedding_matrix = np.zeros((num_tokens, embedding_dim))\n","for word, i in word_index.items():\n","    embedding_vector = embeddings_index.get(word)\n","    if embedding_vector is not None:\n","        # Words not found in embedding index will be all-zeros.\n","        # This includes the representation for \"padding\" and \"OOV\"\n","        embedding_matrix[i] = embedding_vector\n","        hits += 1\n","    else:\n","        misses += 1\n","print(f\"Converted {hits} words ({misses} misses)\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7Cs5mwGf2-Vx","executionInfo":{"status":"ok","timestamp":1704373390003,"user_tz":-540,"elapsed":10,"user":{"displayName":"Heeseong Yang","userId":"11765788859671095501"}},"outputId":"847c20fa-698f-4611-9072-1768b54c6ac5"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["Converted 29730 words (35111 misses)\n"]}]},{"cell_type":"code","source":["# create embedding layer\n","embedding_layer = tf.keras.layers.Embedding(num_tokens,\n","                                            embedding_dim,\n","                                            trainable=False)    # set to false to freeze the weights\n","\n","# load pre-trained weights to our embedding layer\n","embedding_layer.build((1,))\n","embedding_layer.set_weights([embedding_matrix])"],"metadata":{"id":"b6sztFy35KyP","executionInfo":{"status":"ok","timestamp":1704374276673,"user_tz":-540,"elapsed":417,"user":{"displayName":"Heeseong Yang","userId":"11765788859671095501"}}},"execution_count":56,"outputs":[]},{"cell_type":"code","source":["# tune model_5\n","# glove input model (instead of token input model) (only section that needs to be changed)\n","glove_inputs = tf.keras.layers.Input(shape=[], dtype=tf.string)\n","glove_vectors = text_vectorizer(glove_inputs)\n","glove_embeddings = embedding_layer(glove_vectors)\n","glove_avgpool = tf.keras.layers.GlobalAveragePooling1D()(glove_embeddings)\n","glove_outputs = tf.keras.layers.Dense(128, activation='relu')(glove_avgpool)\n","glove_model = tf.keras.Model(inputs=glove_inputs, outputs=glove_outputs)\n","\n","# char input model\n","char_inputs = tf.keras.layers.Input(shape=(1,), dtype=tf.string)\n","char_vectors = char_vectorizer(char_inputs)\n","char_embeddings = char_embed(char_vectors)\n","char_bi_lstm = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32))(char_embeddings)\n","char_model = tf.keras.Model(inputs=char_inputs, outputs=char_bi_lstm)\n","\n","# line number model\n","line_number_inputs = tf.keras.layers.Input(shape=(15,), dtype=tf.int32)\n","x = tf.keras.layers.Dense(32, activation='relu')(line_number_inputs)\n","line_number_model = tf.keras.Model(inputs=line_number_inputs, outputs=x)\n","\n","# total lines model\n","total_lines_inputs = tf.keras.layers.Input(shape=(20,), dtype=tf.int32)\n","y = tf.keras.layers.Dense(32, activation='relu')(total_lines_inputs)\n","total_lines_model = tf.keras.Model(inputs=total_lines_inputs, outputs=y)\n","\n","# glove and char hybrid model\n","combined_embeddings = tf.keras.layers.Concatenate()([glove_model.output, char_model.output])\n","z = tf.keras.layers.Dense(256, activation='relu')(combined_embeddings)\n","z = tf.keras.layers.Dropout(0.5)(z)\n","\n","# combine hybrid model with line number and total lines models\n","z = tf.keras.layers.Concatenate()([line_number_model.output, total_lines_model.output, z])\n","\n","# output layer\n","output_layer = tf.keras.layers.Dense(len(class_names), activation='softmax')(z)\n","\n","# build a full model\n","model_6 = tf.keras.Model(inputs=[line_number_model.input,\n","                                 total_lines_model.input,\n","                                 glove_model.input,\n","                                 char_model.input],\n","                         outputs=output_layer)"],"metadata":{"id":"zjuop1lR68qb","executionInfo":{"status":"ok","timestamp":1704374705001,"user_tz":-540,"elapsed":822,"user":{"displayName":"Heeseong Yang","userId":"11765788859671095501"}}},"execution_count":57,"outputs":[]},{"cell_type":"code","source":["# summary\n","model_6.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KFvWpTwqaYeT","executionInfo":{"status":"ok","timestamp":1704374719659,"user_tz":-540,"elapsed":425,"user":{"displayName":"Heeseong Yang","userId":"11765788859671095501"}},"outputId":"c26cf74a-b245-4540-8f33-4dc3ceaa951e"},"execution_count":58,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_22\"\n","__________________________________________________________________________________________________\n"," Layer (type)                Output Shape                 Param #   Connected to                  \n","==================================================================================================\n"," input_18 (InputLayer)       [(None,)]                    0         []                            \n","                                                                                                  \n"," text_vectorization (TextVe  (None, 55)                   0         ['input_18[0][0]']            \n"," ctorization)                                                                                     \n","                                                                                                  \n"," input_19 (InputLayer)       [(None, 1)]                  0         []                            \n","                                                                                                  \n"," embedding_2 (Embedding)     (None, 55, 100)              6484300   ['text_vectorization[4][0]']  \n","                                                                                                  \n"," char_vectorizer (TextVecto  (None, 290)                  0         ['input_19[0][0]']            \n"," rization)                                                                                        \n","                                                                                                  \n"," global_average_pooling1d (  (None, 100)                  0         ['embedding_2[0][0]']         \n"," GlobalAveragePooling1D)                                                                          \n","                                                                                                  \n"," char_embed (Embedding)      (None, 290, 25)              700       ['char_vectorizer[4][0]']     \n","                                                                                                  \n"," dense_15 (Dense)            (None, 128)                  12928     ['global_average_pooling1d[0][\n","                                                                    0]']                          \n","                                                                                                  \n"," bidirectional_4 (Bidirecti  (None, 64)                   14848     ['char_embed[4][0]']          \n"," onal)                                                                                            \n","                                                                                                  \n"," concatenate_6 (Concatenate  (None, 192)                  0         ['dense_15[0][0]',            \n"," )                                                                   'bidirectional_4[0][0]']     \n","                                                                                                  \n"," input_20 (InputLayer)       [(None, 15)]                 0         []                            \n","                                                                                                  \n"," input_21 (InputLayer)       [(None, 20)]                 0         []                            \n","                                                                                                  \n"," dense_18 (Dense)            (None, 256)                  49408     ['concatenate_6[0][0]']       \n","                                                                                                  \n"," dense_16 (Dense)            (None, 32)                   512       ['input_20[0][0]']            \n","                                                                                                  \n"," dense_17 (Dense)            (None, 32)                   672       ['input_21[0][0]']            \n","                                                                                                  \n"," dropout_1 (Dropout)         (None, 256)                  0         ['dense_18[0][0]']            \n","                                                                                                  \n"," concatenate_7 (Concatenate  (None, 320)                  0         ['dense_16[0][0]',            \n"," )                                                                   'dense_17[0][0]',            \n","                                                                     'dropout_1[0][0]']           \n","                                                                                                  \n"," dense_19 (Dense)            (None, 5)                    1605      ['concatenate_7[0][0]']       \n","                                                                                                  \n","==================================================================================================\n","Total params: 6564973 (25.04 MB)\n","Trainable params: 80673 (315.13 KB)\n","Non-trainable params: 6484300 (24.74 MB)\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"code","source":["# model callbacks\n","ckpt_path = 'model_6/model_6.ckpt'\n","mckpt = tf.keras.callbacks.ModelCheckpoint(filepath=ckpt_path,\n","                                           save_best_only=True,\n","                                           save_weights_only=True)"],"metadata":{"id":"liUA-v5MclVG","executionInfo":{"status":"ok","timestamp":1704374783838,"user_tz":-540,"elapsed":501,"user":{"displayName":"Heeseong Yang","userId":"11765788859671095501"}}},"execution_count":59,"outputs":[]},{"cell_type":"code","source":["# compile\n","model_6.compile(optimizer=tf.keras.optimizers.Adam(),\n","                loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.2),\n","                metrics=['accuracy'])"],"metadata":{"id":"nessAxf9clA_","executionInfo":{"status":"ok","timestamp":1704374783839,"user_tz":-540,"elapsed":3,"user":{"displayName":"Heeseong Yang","userId":"11765788859671095501"}}},"execution_count":60,"outputs":[]},{"cell_type":"code","source":["# train\n","history_6 = model_6.fit(train_ds,\n","                        epochs=200,\n","                        validation_data=val_ds,\n","                        validation_steps=int(len(val_ds) * 0.5),\n","                        callbacks=[mckpt, es])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XvSmsivick-N","executionInfo":{"status":"ok","timestamp":1704376133996,"user_tz":-540,"elapsed":1347496,"user":{"displayName":"Heeseong Yang","userId":"11765788859671095501"}},"outputId":"8f5589d4-d9f9-4ff2-da54-bfb6ec40783f"},"execution_count":61,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/200\n","5627/5627 [==============================] - 160s 27ms/step - loss: 0.9843 - accuracy: 0.8012 - val_loss: 0.9349 - val_accuracy: 0.8293\n","Epoch 2/200\n","5627/5627 [==============================] - 156s 28ms/step - loss: 0.9362 - accuracy: 0.8354 - val_loss: 0.9188 - val_accuracy: 0.8403\n","Epoch 3/200\n","5627/5627 [==============================] - 144s 26ms/step - loss: 0.9252 - accuracy: 0.8433 - val_loss: 0.9116 - val_accuracy: 0.8434\n","Epoch 4/200\n","5627/5627 [==============================] - 138s 24ms/step - loss: 0.9179 - accuracy: 0.8483 - val_loss: 0.9068 - val_accuracy: 0.8461\n","Epoch 5/200\n","5627/5627 [==============================] - 137s 24ms/step - loss: 0.9124 - accuracy: 0.8523 - val_loss: 0.9024 - val_accuracy: 0.8500\n","Epoch 6/200\n","5627/5627 [==============================] - 138s 25ms/step - loss: 0.9085 - accuracy: 0.8547 - val_loss: 0.8981 - val_accuracy: 0.8514\n","Epoch 7/200\n","5627/5627 [==============================] - 136s 24ms/step - loss: 0.9068 - accuracy: 0.8568 - val_loss: 0.9018 - val_accuracy: 0.8527\n","Epoch 8/200\n","5627/5627 [==============================] - 135s 24ms/step - loss: 0.9029 - accuracy: 0.8585 - val_loss: 0.8991 - val_accuracy: 0.8515\n","Epoch 9/200\n","5627/5627 [==============================] - 199s 35ms/step - loss: 0.9008 - accuracy: 0.8606 - val_loss: 0.8998 - val_accuracy: 0.8526\n"]}]},{"cell_type":"code","source":["# evaluate\n","model_6.evaluate(val_ds)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B2D7FjnGflsk","executionInfo":{"status":"ok","timestamp":1704376154395,"user_tz":-540,"elapsed":20406,"user":{"displayName":"Heeseong Yang","userId":"11765788859671095501"}},"outputId":"ebed9752-c7a0-41b5-dc8f-b072a2d2dada"},"execution_count":62,"outputs":[{"output_type":"stream","name":"stdout","text":["945/945 [==============================] - 20s 21ms/step - loss: 0.9009 - accuracy: 0.8523\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.9008594751358032, 0.8523103594779968]"]},"metadata":{},"execution_count":62}]},{"cell_type":"code","source":["model_6_pred_probs = model_6.predict(val_ds)\n","model_6_preds = tf.argmax(model_6_pred_probs, axis=1)\n","results_6 = calculate_results(y_true=val_le, y_pred=model_6_preds)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"boI8J8Y2foqp","executionInfo":{"status":"ok","timestamp":1704376208520,"user_tz":-540,"elapsed":52961,"user":{"displayName":"Heeseong Yang","userId":"11765788859671095501"}},"outputId":"9cf1e885-4048-4920-e0e0-deced5cb093c"},"execution_count":63,"outputs":[{"output_type":"stream","name":"stdout","text":["945/945 [==============================] - 52s 11ms/step\n"]}]},{"cell_type":"markdown","source":["## 3. Try replacing the TensorFlow Hub Universal Sentence Encoder pre-trained embedding for the [TensorFlow Hub BERT PubMed expert](https://tfhub.dev/google/experts/bert/pubmed/2) (a language model pre-trained on PubMed texts) pre-trained embedding. Does this affect results?\n","- Note: Using the BERT PubMed expert pre-trained embedding requires an extra preprocessing step for sequences (as detailed in the [TensorFlow Hub guide](https://tfhub.dev/google/experts/bert/pubmed/2)).\n","- Does the BERT model beat the results mentioned in this paper? https://arxiv.org/pdf/1710.06071.pdf"],"metadata":{"id":"VFI2D7NyKKkD"}},{"cell_type":"code","source":["!pip install -q tensorflow_text"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lBN-D4GEv-5d","executionInfo":{"status":"ok","timestamp":1704376472292,"user_tz":-540,"elapsed":9541,"user":{"displayName":"Heeseong Yang","userId":"11765788859671095501"}},"outputId":"8f5c5e67-5acf-46cb-8a19-35e4cff1ff96"},"execution_count":67,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","execution_count":68,"metadata":{"id":"ElzU2g5FJ2PJ","executionInfo":{"status":"ok","timestamp":1704376496724,"user_tz":-540,"elapsed":24438,"user":{"displayName":"Heeseong Yang","userId":"11765788859671095501"}}},"outputs":[],"source":["# Load the BERT encoder and preprocessing models\n","import tensorflow_text as text # Registers the ops.\n","\n","preprocess = hub.load('https://kaggle.com/models/tensorflow/bert/frameworks/TensorFlow2/variations/en-uncased-preprocess/versions/3')\n","bert = hub.load('https://www.kaggle.com/models/google/experts-bert/frameworks/TensorFlow2/variations/pubmed/versions/2')"]},{"cell_type":"code","source":["# reconfigure model_6 to update the token input model\n","bert_inputs = tf.keras.Input(shape=[None], dtype=tf.string)\n","bert_inputs = preprocess([])\n","bert_outputs = bert(bert_inputs, training=False)\n","bert_model = tf.keras.Model(inputs=bert_inputs, outputs=bert_outputs['pooled_output'])\n","\n","bert_model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":460},"id":"fT1U-cf7ilJI","executionInfo":{"status":"error","timestamp":1704377124870,"user_tz":-540,"elapsed":353,"user":{"displayName":"Heeseong Yang","userId":"11765788859671095501"}},"outputId":"79d799a9-dd5f-4e98-f9b1-2bd711b53943"},"execution_count":81,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-81-b00ab6a24a7a>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# reconfigure model_6 to update the token input model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbert_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mbert_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mbert_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mbert_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbert_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbert_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pooled_output'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36m_call_attribute\u001b[0;34m(instance, *args, **kwargs)\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_call_attribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 816\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/core/function/polymorphism/function_type.py\u001b[0m in \u001b[0;36mcanonicalize_to_monomorphic\u001b[0;34m(args, kwargs, default_values, capture_types, polymorphic_type)\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m       parameters.append(\n\u001b[0;32m--> 583\u001b[0;31m           _make_validated_mono_param(name, arg, poly_parameter.kind,\n\u001b[0m\u001b[1;32m    584\u001b[0m                                      \u001b[0mtype_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m                                      poly_parameter.type_constraint))\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/core/function/polymorphism/function_type.py\u001b[0m in \u001b[0;36m_make_validated_mono_param\u001b[0;34m(name, value, kind, type_context, poly_type)\u001b[0m\n\u001b[1;32m    520\u001b[0m ) -> Parameter:\n\u001b[1;32m    521\u001b[0m   \u001b[0;34m\"\"\"Generates and validates a parameter for Monomorphic FunctionType.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m   \u001b[0mmono_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mpoly_type\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmono_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_subtype_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoly_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/core/function/trace_type/trace_type_builder.py\u001b[0m in \u001b[0;36mfrom_value\u001b[0;34m(value, context)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_np_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m     \u001b[0mndarray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdefault_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTENSOR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndarray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/keras_tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         raise TypeError(\n\u001b[0m\u001b[1;32m    286\u001b[0m             \u001b[0;34mf\"You are passing {self}, an intermediate Keras symbolic \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0;34m\"input/output, to a TF API that does not allow registering custom \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: You are passing KerasTensor(type_spec=TensorSpec(shape=(None, None), dtype=tf.string, name='input_27'), name='input_27', description=\"created by layer 'input_27'\"), an intermediate Keras symbolic input/output, to a TF API that does not allow registering custom dispatchers, such as `tf.cond`, `tf.function`, gradient tapes, or `tf.map_fn`. Keras Functional model construction only supports TF API calls that *do* support dispatching, such as `tf.math.add` or `tf.reshape`. Other APIs cannot be called directly on symbolic Kerasinputs/outputs. You can work around this limitation by putting the operation in a custom Keras layer `call` and calling that layer on this symbolic input/output."]}]},{"cell_type":"code","source":["# Define some sentences to feed into the model\n","sentences = [\n","  \"Here We Go Then, You And I is a 1999 album by Norwegian pop artist Morten Abel. It was Abel's second CD as a solo artist.\",\n","  \"The album went straight to number one on the Norwegian album chart, and sold to double platinum.\",\n","  \"Ceylon spinach is a common name for several plants and may refer to: Basella alba Talinum fruticosum\",\n","  \"A solar eclipse occurs when the Moon passes between Earth and the Sun, thereby totally or partly obscuring the image of the Sun for a viewer on Earth.\",\n","  \"A partial solar eclipse occurs in the polar regions of the Earth when the center of the Moon's shadow misses the Earth.\",\n","]\n","\n","# Convert the sentences to bert inputs\n","bert_inputs = preprocess(sentences)\n","\n","# Feed the inputs to the model to get the pooled and sequence outputs\n","bert_outputs = bert(bert_inputs, training=False)\n","pooled_output = bert_outputs['pooled_output']\n","sequence_output = bert_outputs['sequence_output']\n","\n","print('\\nSentences:')\n","print(sentences)\n","print('\\nPooled output:')\n","print(pooled_output)\n","print('\\nSequence output:')\n","print(sequence_output)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wLiTL6UWxx7n","executionInfo":{"status":"ok","timestamp":1704377007911,"user_tz":-540,"elapsed":2514,"user":{"displayName":"Heeseong Yang","userId":"11765788859671095501"}},"outputId":"99fd590d-3c4e-4a1f-eba1-487e730d570c"},"execution_count":78,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Sentences:\n","[\"Here We Go Then, You And I is a 1999 album by Norwegian pop artist Morten Abel. It was Abel's second CD as a solo artist.\", 'The album went straight to number one on the Norwegian album chart, and sold to double platinum.', 'Ceylon spinach is a common name for several plants and may refer to: Basella alba Talinum fruticosum', 'A solar eclipse occurs when the Moon passes between Earth and the Sun, thereby totally or partly obscuring the image of the Sun for a viewer on Earth.', \"A partial solar eclipse occurs in the polar regions of the Earth when the center of the Moon's shadow misses the Earth.\"]\n","\n","Pooled output:\n","tf.Tensor(\n","[[ 0.1677935  -0.39312428  0.537474   ...  0.5847805  -0.43331927\n","  -0.6014683 ]\n"," [ 0.41831735 -0.11058065  0.37715095 ...  0.42176116 -0.25798553\n","   0.09233515]\n"," [-0.55007035  0.36924163 -0.06870158 ... -0.5558884  -0.7557076\n","  -0.4532629 ]\n"," [ 0.05911616  0.08547181 -0.5964454  ... -0.55465883 -0.7894638\n","  -0.7985187 ]\n"," [ 0.30475476 -0.02680803 -0.61563677 ... -0.6493112  -0.6677756\n","  -0.7691776 ]], shape=(5, 768), dtype=float32)\n","\n","Sequence output:\n","tf.Tensor(\n","[[[ 1.6939539e-01 -4.1549009e-01  6.0059667e-01 ...  6.6969705e-01\n","   -4.6397606e-01 -6.9544464e-01]\n","  [-2.5725535e-01 -1.5093766e+00  1.8063663e-01 ...  6.8269587e-01\n","   -2.0926888e-01 -2.1222153e+00]\n","  [ 3.5181576e-01 -1.0342586e+00  1.3441205e+00 ...  5.5813611e-01\n","   -5.9879577e-01 -3.9328039e+00]\n","  ...\n","  [ 7.8125238e-02 -3.6869043e-01  5.6604081e-01 ...  5.1112044e-01\n","    2.0302865e-01 -1.2489709e+00]\n","  [-1.7814702e-01  3.3987805e-01  8.4622639e-01 ...  7.7170864e-02\n","   -1.5028018e-01 -1.5017922e+00]\n","  [ 2.3332658e-01 -2.3472118e-01  5.1837027e-01 ...  3.7725312e-01\n","    4.3199363e-01 -1.8267348e-01]]\n","\n"," [[ 4.4565073e-01 -1.1103472e-01  3.9673397e-01 ...  4.4983232e-01\n","   -2.6394910e-01  9.2598915e-02]\n","  [ 2.4666092e-01 -1.2717507e+00  1.6192453e+00 ... -2.4548367e-02\n","   -1.4153912e+00  3.4875453e-01]\n","  [ 2.1638906e-01 -6.6150403e-01  5.3284454e-01 ...  3.1224141e-01\n","   -4.9641639e-01  6.3301450e-01]\n","  ...\n","  [ 1.1355307e+00 -1.3347906e-01  7.6311547e-01 ...  4.9211830e-03\n","   -1.0210981e+00  8.2461369e-01]\n","  [ 3.8266003e-02  6.9692135e-03 -2.7941555e-01 ...  2.0832978e-01\n","    2.6463106e-01 -2.3371336e+00]\n","  [ 3.2590821e-02 -1.3114330e-01 -1.8134311e-01 ...  2.1469420e-01\n","    2.8813311e-01 -2.2424977e+00]]\n","\n"," [[-6.1848223e-01  3.8754472e-01 -6.8809986e-02 ... -6.2686300e-01\n","   -9.8613071e-01 -4.8879921e-01]\n","  [ 1.8122809e-01 -5.9486538e-02  6.4911675e-01 ... -3.8966984e-01\n","    2.6629019e-01 -1.0137131e+00]\n","  [-1.0368946e+00  3.0329567e-01  1.0561929e+00 ...  1.3617057e-01\n","   -6.1627752e-01 -3.1232011e+00]\n","  ...\n","  [ 4.9830118e-01 -4.3752313e-01  9.3645871e-01 ... -5.1153678e-01\n","   -5.7077885e-01  1.0031395e+00]\n","  [ 3.9972913e-01 -1.4228048e+00  6.2474835e-01 ... -4.7766393e-01\n","   -3.1062177e-01  3.4295499e-01]\n","  [ 5.0013936e-01 -4.3766171e-01  9.3746758e-01 ... -5.1147127e-01\n","   -5.7148600e-01  1.0036418e+00]]\n","\n"," [[ 5.9185177e-02  8.5680872e-02 -6.8761146e-01 ... -6.2508535e-01\n","   -1.0700066e+00 -1.0945110e+00]\n","  [ 6.9566226e-01 -1.3789728e+00 -3.6365122e-02 ... -3.3129606e-01\n","    9.8075998e-01  8.5882008e-01]\n","  [-7.3299342e-01  9.5097893e-01 -1.6575778e-01 ... -3.9205274e-01\n","   -8.6700082e-02  1.4566098e+00]\n","  ...\n","  [-2.8002238e-01 -1.5338427e-01  5.0576776e-01 ...  8.2769081e-02\n","    6.5646803e-01 -2.2723341e+00]\n","  [-2.9430133e-01 -5.9678102e-01  6.3051891e-01 ...  5.3368062e-02\n","    3.9921170e-01 -1.5987216e+00]\n","  [-2.4084634e-01 -1.3933420e-01  4.9979004e-01 ...  3.1306818e-02\n","    7.3739284e-01 -2.6635280e+00]]\n","\n"," [[ 3.1475288e-01 -2.6814461e-02 -7.1794820e-01 ... -7.7410692e-01\n","   -8.0671763e-01 -1.0183105e+00]\n","  [ 8.6472374e-01 -1.5987831e+00  1.9729300e-01 ... -4.9154854e-01\n","    1.3596277e+00  2.7656525e-02]\n","  [ 7.1079093e-01 -1.8914902e+00  8.2558900e-02 ... -9.0913102e-02\n","    7.0284629e-01  1.0546553e+00]\n","  ...\n","  [-2.0835336e-01 -8.2237530e-01  4.3287823e-01 ...  2.4113056e-01\n","    9.7707152e-02 -3.0947804e+00]\n","  [-4.1487634e-02 -3.3032298e-02  3.1778944e-01 ...  7.1733892e-03\n","    8.0241317e-01 -3.8020422e+00]\n","  [ 2.0806541e-01 -8.5062683e-01  4.0373677e-01 ... -3.6978722e-04\n","    4.4686535e-01 -5.4236138e-01]]], shape=(5, 128, 768), dtype=float32)\n"]}]},{"cell_type":"code","source":["# char input model\n","char_inputs = tf.keras.layers.Input(shape=(1,), dtype=tf.string)\n","char_vectors = char_vectorizer(char_inputs)\n","char_embeddings = char_embed(char_vectors)\n","char_bi_lstm = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32))(char_embeddings)\n","char_model = tf.keras.Model(inputs=char_inputs, outputs=char_bi_lstm)\n","\n","# line number model\n","line_number_inputs = tf.keras.layers.Input(shape=(15,), dtype=tf.int32)\n","x = tf.keras.layers.Dense(32, activation='relu')(line_number_inputs)\n","line_number_model = tf.keras.Model(inputs=line_number_inputs, outputs=x)\n","\n","# total lines model\n","total_lines_inputs = tf.keras.layers.Input(shape=(20,), dtype=tf.int32)\n","y = tf.keras.layers.Dense(32, activation='relu')(total_lines_inputs)\n","total_lines_model = tf.keras.Model(inputs=total_lines_inputs, outputs=y)\n","\n","# glove and char hybrid model\n","combined_embeddings = tf.keras.layers.Concatenate()([bert_model.output, char_model.output])\n","z = tf.keras.layers.Dense(256, activation='relu')(combined_embeddings)\n","z = tf.keras.layers.Dropout(0.5)(z)\n","\n","# combine hybrid model with line number and total lines models\n","z = tf.keras.layers.Concatenate()([line_number_model.output, total_lines_model.output, z])\n","\n","# output layer\n","output_layer = tf.keras.layers.Dense(len(class_names), activation='softmax')(z)\n","\n","# build a full model\n","model_7 = tf.keras.Model(inputs=[line_number_model.input,\n","                                 total_lines_model.input,\n","                                 bert_model.input,\n","                                 char_model.input],\n","                         outputs=output_layer)"],"metadata":{"id":"72jU3Zl-uqyH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# update checkpoint\n","ckpt_path = 'model_7/model_7.ckpt'\n","\n","mckpt = tf.keras.callbacks.ModelCheckpoint(filepath=ckpt_path,\n","                                           save_best_only=True,\n","                                           save_weights_only=True)"],"metadata":{"id":"TAuHJAnSuYoC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# compile\n","model_7.compile(optimizer='adam',\n","                loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.2),\n","                metrics=['accuracy'])"],"metadata":{"id":"-cOcXse3keDY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# train\n","history_7 = model_7.fit(train_ds,\n","                        epochs=300,\n","                        validation_data=val_ds,\n","                        validation_steps=int(len(val_ds) * 0.5),\n","                        callbacks=[mckpt, es])"],"metadata":{"id":"2pIVTX0bu4Ev"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# evaluate\n","model_7.evaluate(val_ds)"],"metadata":{"id":"f7kYXox3vBEB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# get results\n","model_7_preds = tf.argmax(model_7.predict(val_ds), axis=1)\n","results_7 = calculate_results(y_true=val_le, y_pred=model_7_preds)"],"metadata":{"id":"EmXu8OtYvDtb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"fUmQEvInvWGU"}},{"cell_type":"markdown","source":["## 4. What happens if you were to merge our `line_number` and `total_lines` features for each sequence? For example, created a `X_of_Y` feature instead? Does this affect model performance?\n","- Another example: `line_number=1` and `total_lines=11` turns into `line_of_X=1_of_11`."],"metadata":{"id":"PPgwbhlnKQuw"}},{"cell_type":"code","source":["train_df"],"metadata":{"id":"dLEG19KJKUyK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 5. Write a function (or series of functions) to take a sample abstract string, preprocess it (in the same way our model has been trained), make a prediction on each sequence in the abstract, and return the abstract in the format:\n","- `PREDICTED_LABEL: SEQUENCE`\n","- `PREDICTED_LABEL: SEQUENCE`\n","- `PREDICTED_LABEL: SEQUENCE`\n","- `PREDICTED_LABEL: SEQUENCE`\n","- ...\n","    - You can find your own unstructured RCT abstract from PubMed or try this one from: [*Baclofen promotes alcohol abstinence in alcohol dependent cirrhotic patients with hepatitis C virus (HCV) infection*](https://pubmed.ncbi.nlm.nih.gov/22244707/)."],"metadata":{"id":"3Y2vrtQPKVUp"}},{"cell_type":"code","source":[],"metadata":{"id":"zyQUbRgJKj33"},"execution_count":null,"outputs":[]}]}