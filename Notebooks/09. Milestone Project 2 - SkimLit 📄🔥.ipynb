{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","toc_visible":true,"authorship_tag":"ABX9TyP5eL/rzlprpsuLoLTE9Zy/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# 09. Milestone Project 2: SkimLit ðŸ“„ðŸ”¥\n","\n","In the previous notebook ([NLP fundamentals in TensorFlow](https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/08_introduction_to_nlp_in_tensorflow.ipynb)), we went through some fundamental natural language processing concepts. The main ones are **tokenization** (turning words into numbers) and **creating embeddings** (creating a numerical representation of words).\n","\n","In this project, we're going to be putting what we've learned into practice.\n","\n","More specifically, we're going to be replicating the deep learning model behind the 2017 paper [*PubMed 200k RCT: a Dataset for Sequential Sentence Classification in Medical Abstracts*](https://arxiv.org/abs/1710.06071).\n","\n","When it was released, the paper presented a new dataset called PubMed 200k RCT which consists of ~200,000 labeled Randomized Controlled Trial (RCT) abstracts.\n","\n","The goal of the dataset was to explore the ability of NLP models to classify sentences which appear in sequential order.\n","\n","In other words, given the abstract of an RCT, what role does each sentence serve in the abstract?\n","\n","![image0](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/09-skimlit-overview-input-and-output.png)\n","*Example inputs ([harder to read abstract from PubMed](https://pubmed.ncbi.nlm.nih.gov/28942748/)) and outputs ([easier to read abstract](https://pubmed.ncbi.nlm.nih.gov/32537182/)) of the model we're going to build. The model will take an abstract wall of text and predict the section label each sentence should have.*"],"metadata":{"id":"omkvxmKHxYE_"}},{"cell_type":"markdown","source":["### Model Input\n","\n","For example, can we train an NLP model that takes the following input (note: the following sample has had all numerical symbols replaced with \"@\"):\n","\n","> To investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( OA ). A total of @ patients with primary knee OA were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks. Outcome measures included pain reduction and improvement in function scores and systemic inflammation markers. Pain was assessed using the visual analog pain scale ( @-@ mm ). Secondary outcome measures included the Western Ontario and McMaster Universities Osteoarthritis Index scores , patient global assessment ( PGA ) of the severity of knee OA , and @-min walk distance ( @MWD )., Serum levels of interleukin @ ( IL-@ ) , IL-@ , tumor necrosis factor ( TNF ) - , and high-sensitivity C-reactive protein ( hsCRP ) were measured. There was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , PGA , and @MWD at @ weeks. The mean difference between treatment arms ( @ % CI ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively. Further , there was a clinically relevant reduction in the serum levels of IL-@ , IL-@ , TNF - , and hsCRP at @ weeks in the intervention group when compared to the placebo group. These differences remained significant at @ weeks. The Outcome Measures in Rheumatology Clinical Trials-Osteoarthritis Research Society International responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ). Low-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee OA ( ClinicalTrials.gov identifier NCT@ )."],"metadata":{"id":"BiluAWPVzeEL"}},{"cell_type":"markdown","source":["### Model output\n","\n","And returns the following output:\n","```\n","['###24293578\\n',\n"," 'OBJECTIVE\\tTo investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .\\n',\n"," 'METHODS\\tA total of @ patients with primary knee OA were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .\\n',\n"," 'METHODS\\tOutcome measures included pain reduction and improvement in function scores and systemic inflammation markers .\\n',\n"," 'METHODS\\tPain was assessed using the visual analog pain scale ( @-@ mm ) .\\n',\n"," 'METHODS\\tSecondary outcome measures included the Western Ontario and McMaster Universities Osteoarthritis Index scores , patient global assessment ( PGA ) of the severity of knee OA , and @-min walk distance ( @MWD ) .\\n',\n"," 'METHODS\\tSerum levels of interleukin @ ( IL-@ ) , IL-@ , tumor necrosis factor ( TNF ) - , and high-sensitivity C-reactive protein ( hsCRP ) were measured .\\n',\n"," 'RESULTS\\tThere was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , PGA , and @MWD at @ weeks .\\n',\n"," 'RESULTS\\tThe mean difference between treatment arms ( @ % CI ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .\\n',\n"," 'RESULTS\\tFurther , there was a clinically relevant reduction in the serum levels of IL-@ , IL-@ , TNF - , and hsCRP at @ weeks in the intervention group when compared to the placebo group .\\n',\n"," 'RESULTS\\tThese differences remained significant at @ weeks .\\n',\n"," 'RESULTS\\tThe Outcome Measures in Rheumatology Clinical Trials-Osteoarthritis Research Society International responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .\\n',\n"," 'CONCLUSIONS\\tLow-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee OA ( ClinicalTrials.gov identifier NCT@ ) .\\n',\n"," '\\n']\n"," ```"],"metadata":{"id":"ZJnL_Sjezr4r"}},{"cell_type":"markdown","source":["### Problem in a sentence\n","\n","The number of RCT papers released is continuing to increase, those without structured abstracts can be hard to read and in turn, slow down researchers moving through the literature."],"metadata":{"id":"VIL2bJ2T0Kpn"}},{"cell_type":"markdown","source":["### Solution in a sentence\n","\n","Create an NLP model to classify abstract sentences into the role they play (e.g. objective, methods, results, etc) to enable researchers to skim through the literature (hence SkimLit ðŸ¤“ðŸ”¥) and dive deeper when necessary.\n","\n","1. Where our data is coming from: [PubMed 200k RCT: a Dataset for Sequential Sentence Classification in Medical Abstracts](https://arxiv.org/abs/1710.06071)\n","2. Where our model is coming from: [Neural networks for joint sentence classification in medical paper abstracts](https://arxiv.org/pdf/1612.05251.pdf)\n","\n","> ðŸ“– Resources: Before going through the code in this notebook, you might want to get a background of what we're going to be doing. To do so, spend an hour (or two) going through the following papers and then return to this notebook:"],"metadata":{"id":"tXpOZTZu0bJt"}},{"cell_type":"markdown","source":["## What we're going to cover\n","\n","Time to take what we've learned in the NLP fundamentals notebook and build our biggest NLP model yet:\n","\n","- Downloading a text dataset ([PubMed RCT200k from GitHub](https://github.com/Franck-Dernoncourt/pubmed-rct))\n","- Writing a preprocessing function to prepare our data for modeling\n","- Setting up a series of modeling experiments\n","    - Making a baseline (TF-IDF classifier)\n","    - Deep models with different combinations of token embeddings, character embeddings, pre-trained embeddings, positional embeddings\n","- Building our first multimodal model (taking multiple types of data inputs)\n","    - Replicating the model architecture from https://arxiv.org/abs/1612.05251\n","- Find the most wrong predictions\n","- Making predictions on PubMed abstracts from the wild"],"metadata":{"id":"nLeTeFf408MH"}},{"cell_type":"markdown","source":["## Confirm access to a GPU\n","\n","Since we're going to be building deep learning models, let's make sure we have a GPU.\n","\n","In Google Colab, you can set this up by going to Runtime -> Change runtime type -> Hardware accelerator -> GPU.\n","\n","If you don't have access to a GPU, the models we're building here will likely take up to 10x longer to run."],"metadata":{"id":"K9bl4Xt21Vbi"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"ocw8KncCxUlG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1703583414890,"user_tz":-540,"elapsed":15,"user":{"displayName":"Hee Seong Yang","userId":"11765788859671095501"}},"outputId":"f3245c9d-8114-46f6-c2a8-19ffb1659c2f"},"outputs":[{"output_type":"stream","name":"stdout","text":["GPU 0: Tesla T4 (UUID: GPU-bc7f5a24-d032-5c66-80c0-26d8f3b20a5e)\n"]}],"source":["# Check for GPU\n","!nvidia-smi -L"]},{"cell_type":"markdown","source":["## Get data\n","\n","Before we can start building a model, we've got to download the PubMed 200k RCT dataset.\n","\n","In a phenomenal act of kindness, the paper's authors have made the data they used for their research available publicly and for free in the form of `.txt` files on [GitHub](https://github.com/Franck-Dernoncourt/pubmed-rct).\n","\n","We can copy them to our local directory using `git clone https://github.com/Franck-Dernoncourt/pubmed-rct`."],"metadata":{"id":"QIG93oGCJLhh"}},{"cell_type":"code","source":["!git clone https://github.com/Franck-Dernoncourt/pubmed-rct.git\n","!ls pubmed-rct"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8Q7KsGs6JkCP","executionInfo":{"status":"ok","timestamp":1703583430562,"user_tz":-540,"elapsed":15680,"user":{"displayName":"Hee Seong Yang","userId":"11765788859671095501"}},"outputId":"9a4012db-35ad-445f-aecb-4f4348f46c92"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'pubmed-rct'...\n","remote: Enumerating objects: 39, done.\u001b[K\n","remote: Counting objects: 100% (14/14), done.\u001b[K\n","remote: Compressing objects: 100% (9/9), done.\u001b[K\n","remote: Total 39 (delta 8), reused 5 (delta 5), pack-reused 25\u001b[K\n","Receiving objects: 100% (39/39), 177.08 MiB | 16.96 MiB/s, done.\n","Resolving deltas: 100% (15/15), done.\n","Updating files: 100% (13/13), done.\n","PubMed_200k_RCT\t\t\t\t       PubMed_20k_RCT_numbers_replaced_with_at_sign\n","PubMed_200k_RCT_numbers_replaced_with_at_sign  README.md\n","PubMed_20k_RCT\n"]}]},{"cell_type":"markdown","source":["Checking the contents of the downloaded repository, you can see there are four folders.\n","\n","Each contains a different version of the PubMed 200k RCT dataset.\n","\n","Looking at the `README` file from the GitHub page, we get the following information:\n","\n","- PubMed 20k is a subset of PubMed 200k. I.e., any abstract present in PubMed 20k is also present in PubMed 200k.\n","- `PubMed_200k_RCT` is the same as `PubMed_200k_RCT_numbers_replaced_with_at_sign`, except that in the latter all numbers had been replaced by `@`. (same for `PubMed_20k_RCT` vs. `PubMed_20k_RCT_numbers_replaced_with_at_sign`).\n","- Since the Github file size limit is 100 MiB, we had to compress `PubMed_200k_RCT\\train.7z` and `PubMed_200k_RCT_numbers_replaced_with_at_sign\\train.zip`. To uncompress `train.7z`, you may use 7-Zip on Windows, Keka on Mac OS X, or p7zip on Linux.\n","\n","To begin with, the dataset we're going to be focused on is `PubMed_20k_RCT_numbers_replaced_with_at_sign`.\n","\n","Why this one?\n","\n","Rather than working with the whole 200k dataset, we'll keep our experiments quick by starting with a smaller subset. We could've chosen the dataset with numbers instead of having them replaced with @ but we didn't.\n","\n","Let's check the file contents."],"metadata":{"id":"YJNfaij_JnOI"}},{"cell_type":"code","source":["# Check what files are in the PubMed_20K dataset\n","!ls pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1u7Qvhfkz0bX","executionInfo":{"status":"ok","timestamp":1703583430563,"user_tz":-540,"elapsed":17,"user":{"displayName":"Hee Seong Yang","userId":"11765788859671095501"}},"outputId":"34d22d92-bf46-4c0a-dfef-cf94fddd10c2"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["dev.txt  test.txt  train.txt\n"]}]},{"cell_type":"markdown","source":["Beautiful, looks like we've got three separate text files:\n","\n","- `train.txt` - training samples.\n","- `dev.txt` - dev is short for development set, which is another name for validation set (in our case, we'll be using and referring to this file as our validation set).\n","- `test.txt` - test samples.\n","\n","To save ourselves from typing out the file path to our target directory each time, let's turn it into a variable."],"metadata":{"id":"TxdVihoh0Pcq"}},{"cell_type":"code","source":["# Start by using the 20k dataset\n","data_dir = \"pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/\""],"metadata":{"id":"EOCOm2Ipz2DX","executionInfo":{"status":"ok","timestamp":1703583430563,"user_tz":-540,"elapsed":12,"user":{"displayName":"Hee Seong Yang","userId":"11765788859671095501"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Check all of the file names in the target directory\n","import os\n","\n","filenames = [data_dir + filename for filename in os.listdir(data_dir)]\n","filenames"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pIpsTO4c0jCt","executionInfo":{"status":"ok","timestamp":1703583430563,"user_tz":-540,"elapsed":11,"user":{"displayName":"Hee Seong Yang","userId":"11765788859671095501"}},"outputId":"20429322-7a83-4bdf-9090-bca39ba894d8"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/train.txt',\n"," 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/dev.txt',\n"," 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/test.txt']"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["## Preprocess data\n","\n","Okay, now we've downloaded some text data, do you think we're ready to model it?\n","\n","Wait...\n","\n","We've downloaded the data but we haven't even looked at it yet.\n","\n","What's the motto for getting familiar with any new dataset?\n","\n","I'll give you a clue, the word begins with \"v\" and we say it three times.\n","\n","> Vibe, vibe, vibe?\n","\n","Sort of... we've definitely got to the feel the vibe of our data.\n","\n","> Values, values, values?\n","\n","Right again, we want to see lots of values but not quite what we're looking for.\n","\n","> Visualize, visualize, visualize?\n","\n","Boom! That's it. To get familiar with and understand how we have to prepare our data for our deep learning models, we've got to visualize it.\n","\n","Because our data is in the form of text files, let's write some code to read each of the lines in a target file."],"metadata":{"id":"MY6gXMhw0z0K"}},{"cell_type":"code","source":["# Create a function to read the lines of a document\n","def get_lines(filename):\n","    \"\"\"\n","    Reads filename (a text file) and returns the lines of text as a list.\n","\n","    Args:\n","        filename: a string containing the target filepath to read.\n","\n","    Returns:\n","        A list of strings with one string per line from the target filename.\n","        For example:\n","        [\"this is the first line of filename\",\n","        \"this is the second line of filename\",\n","        \"...\"]\n","    \"\"\"\n","    with open(filename, \"r\") as f:\n","        return f.readlines()"],"metadata":{"id":"gBYkWuU-3oT9","executionInfo":{"status":"ok","timestamp":1703583430563,"user_tz":-540,"elapsed":8,"user":{"displayName":"Hee Seong Yang","userId":"11765788859671095501"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["Alright, we've got a little function, `get_lines()` which takes the file path of a text file, opens it, reads each of the lines, and returns them.\n","\n","Let's try it out on the training data (`train.txt`)."],"metadata":{"id":"QVgwTMrO4DzF"}},{"cell_type":"code","source":["train_lines = get_lines(data_dir + \"train.txt\")\n","train_lines[:20] # the whole first example of an abstract + a little more of a next one"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f_wUN_1p38UH","executionInfo":{"status":"ok","timestamp":1703583431037,"user_tz":-540,"elapsed":481,"user":{"displayName":"Hee Seong Yang","userId":"11765788859671095501"}},"outputId":"d7a78112-1e2d-4c89-d5c3-7bf259097da4"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['###24293578\\n',\n"," 'OBJECTIVE\\tTo investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .\\n',\n"," 'METHODS\\tA total of @ patients with primary knee OA were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .\\n',\n"," 'METHODS\\tOutcome measures included pain reduction and improvement in function scores and systemic inflammation markers .\\n',\n"," 'METHODS\\tPain was assessed using the visual analog pain scale ( @-@ mm ) .\\n',\n"," 'METHODS\\tSecondary outcome measures included the Western Ontario and McMaster Universities Osteoarthritis Index scores , patient global assessment ( PGA ) of the severity of knee OA , and @-min walk distance ( @MWD ) .\\n',\n"," 'METHODS\\tSerum levels of interleukin @ ( IL-@ ) , IL-@ , tumor necrosis factor ( TNF ) - , and high-sensitivity C-reactive protein ( hsCRP ) were measured .\\n',\n"," 'RESULTS\\tThere was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , PGA , and @MWD at @ weeks .\\n',\n"," 'RESULTS\\tThe mean difference between treatment arms ( @ % CI ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .\\n',\n"," 'RESULTS\\tFurther , there was a clinically relevant reduction in the serum levels of IL-@ , IL-@ , TNF - , and hsCRP at @ weeks in the intervention group when compared to the placebo group .\\n',\n"," 'RESULTS\\tThese differences remained significant at @ weeks .\\n',\n"," 'RESULTS\\tThe Outcome Measures in Rheumatology Clinical Trials-Osteoarthritis Research Society International responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .\\n',\n"," 'CONCLUSIONS\\tLow-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee OA ( ClinicalTrials.gov identifier NCT@ ) .\\n',\n"," '\\n',\n"," '###24854809\\n',\n"," 'BACKGROUND\\tEmotional eating is associated with overeating and the development of obesity .\\n',\n"," 'BACKGROUND\\tYet , empirical evidence for individual ( trait ) differences in emotional eating and cognitive mechanisms that contribute to eating during sad mood remain equivocal .\\n',\n"," 'OBJECTIVE\\tThe aim of this study was to test if attention bias for food moderates the effect of self-reported emotional eating during sad mood ( vs neutral mood ) on actual food intake .\\n',\n"," 'OBJECTIVE\\tIt was expected that emotional eating is predictive of elevated attention for food and higher food intake after an experimentally induced sad mood and that attentional maintenance on food predicts food intake during a sad versus a neutral mood .\\n',\n"," 'METHODS\\tParticipants ( N = @ ) were randomly assigned to one of the two experimental mood induction conditions ( sad/neutral ) .\\n']"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["Reading the lines from the training text file results in a list of strings containing different abstract samples, the sentences in a sample along with the role the sentence plays in the abstract.\n","\n","The role of each sentence is prefixed at the start of each line separated by a tab (`\\t`) and each sentence finishes with a new line (`\\n`).\n","\n","Different abstracts are separated by abstract IDs (lines beginning with `###`) and newlines (`\\n`).\n","\n","Knowing this, it looks like we've got a couple of steps to do to get our samples ready to pass as training data to our future machine-learning model.\n","\n","Let's write a function to perform the following steps:\n","\n","- Take a target file of abstract samples.\n","- Read the lines in the target file.\n","- For each line in the target file:\n","    - If the line begins with `###` mark it as an abstract ID and the beginning of a new abstract.\n","        - Keep count of the number of lines in a sample.\n","    - If the line begins with `\\n` mark it as the end of an abstract sample.\n","        - Keep count of the total lines in a sample.\n","    - Record the text before the `\\t` as the label of the line.\n","    - Record the text after the `\\t` as the text of the line.\n","- Return all of the lines in the target text file as a list of dictionaries containing the key/value pairs:\n","    - `\"line_number\"` - the position of the line in the abstract (e.g. `3`).\n","    - `\"target\"` - the role of the line in the abstract (e.g. `OBJECTIVE`).\n","    - `\"text\"` - the text of the line in the abstract.\n","    - `\"total_lines\"` - the total lines in an abstract sample (e.g. `14`).\n","- Abstract IDs and newlines should be omitted from the returned preprocessed data.\n","\n","Example returned preprocessed sample (a single line from an abstract):\n","```\n","[{'line_number': 0,\n","  'target': 'OBJECTIVE',\n","  'text': 'to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n","  'total_lines': 11},\n","  ...]\n","  ```"],"metadata":{"id":"p68Lnfz44wtP"}},{"cell_type":"code","source":["def preprocess_text_with_line_numbers(filename):\n","    \"\"\"Returns a list of dictionaries of abstract line data.\n","\n","    Takes in filename, reads its contents, and sorts through each line,\n","    extracting things like the target label, the text of the sentence,\n","    how many sentences are in the current abstract, and what sentence number\n","    the target line is.\n","\n","    Args:\n","        filename: a string of the target text file to read\n","        and extract line data from.\n","\n","    Returns:\n","        A list of dictionaries each containing a line from an abstract,\n","        the line's label, the line's position in the abstract, and\n","        the total number of lines in the abstract where the line is from.\n","\n","        For example:\n","        [{\"target\": 'CONCLUSION',\n","          \"text\": The study couldn't have gone better, turns out people are kinder than you think\",\n","          \"line_number\": 8,\n","          \"total_lines\": 8}]\n","    \"\"\"\n","    input_lines = get_lines(filename)   # get all lines from filename\n","    abstract_lines = \"\"                 # create an empty abstract\n","    abstract_samples = []               # create an empty list of abstracts\n","\n","    # Loop through each line in a target file\n","    for line in input_lines:\n","        if line.startswith(\"###\"):                              # check to see if the line is an ID line\n","            abstract_id = line\n","            abstract_lines = \"\"                                 # reset abstract string\n","        elif line.isspace():                                    # check to see if the line is a new line\n","            abstract_line_split = abstract_lines.splitlines()   # split abstract into separate lines\n","\n","            # Iterate through each line in the abstract and count them at the same time\n","            for abstract_line_number, abstract_line in enumerate(abstract_line_split):\n","                line_data = {}                                          # create an empty dict to store data from the line\n","                target_text_split = abstract_line.split(\"\\t\")           # split target label from text\n","                line_data[\"target\"] = target_text_split[0]              # get target label\n","                line_data[\"text\"] = target_text_split[1].lower()        # get target text and lower it\n","                line_data[\"line_number\"] = abstract_line_number         # what number line does the line appear in the abstract?\n","                line_data[\"total_lines\"] = len(abstract_line_split) - 1 # how many total lines are in the abstract? (start from 0)\n","                abstract_samples.append(line_data)                      # add line data to abstract samples list\n","\n","        else:\n","            abstract_lines += line\n","\n","    return abstract_samples"],"metadata":{"id":"lFPot9WE4laV","executionInfo":{"status":"ok","timestamp":1703583431037,"user_tz":-540,"elapsed":7,"user":{"displayName":"Hee Seong Yang","userId":"11765788859671095501"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["Beautiful! That's one good-looking function. Let's use it to preprocess each of our RCT 20k datasets."],"metadata":{"id":"k__J4WSpBBsD"}},{"cell_type":"code","source":["# Get data from the file and preprocess it\n","%%time\n","train_samples = preprocess_text_with_line_numbers(data_dir + \"train.txt\")\n","val_samples = preprocess_text_with_line_numbers(data_dir + \"dev.txt\") # dev is another name for validation set\n","test_samples = preprocess_text_with_line_numbers(data_dir + \"test.txt\")\n","len(train_samples), len(val_samples), len(test_samples)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vkJI3p8nA_pt","executionInfo":{"status":"ok","timestamp":1703583432893,"user_tz":-540,"elapsed":1861,"user":{"displayName":"Hee Seong Yang","userId":"11765788859671095501"}},"outputId":"590d8f17-4389-4e19-d3c9-24dc2d3f83e2"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["CPU times: user 727 ms, sys: 138 ms, total: 864 ms\n","Wall time: 1.91 s\n"]},{"output_type":"execute_result","data":{"text/plain":["(180040, 30212, 30135)"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["How do our training samples look?"],"metadata":{"id":"yiqbqbZdDNLt"}},{"cell_type":"code","source":["# Check the first abstract of our training data\n","train_samples[:14]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wQPNk8GGBYDu","executionInfo":{"status":"ok","timestamp":1703583432894,"user_tz":-540,"elapsed":5,"user":{"displayName":"Hee Seong Yang","userId":"11765788859671095501"}},"outputId":"d8e38d08-7400-43ab-d395-7ace1815a9b9"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'target': 'OBJECTIVE',\n","  'text': 'to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n","  'line_number': 0,\n","  'total_lines': 11},\n"," {'target': 'METHODS',\n","  'text': 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n","  'line_number': 1,\n","  'total_lines': 11},\n"," {'target': 'METHODS',\n","  'text': 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n","  'line_number': 2,\n","  'total_lines': 11},\n"," {'target': 'METHODS',\n","  'text': 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n","  'line_number': 3,\n","  'total_lines': 11},\n"," {'target': 'METHODS',\n","  'text': 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .',\n","  'line_number': 4,\n","  'total_lines': 11},\n"," {'target': 'METHODS',\n","  'text': 'serum levels of interleukin @ ( il-@ ) , il-@ , tumor necrosis factor ( tnf ) - , and high-sensitivity c-reactive protein ( hscrp ) were measured .',\n","  'line_number': 5,\n","  'total_lines': 11},\n"," {'target': 'RESULTS',\n","  'text': 'there was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , pga , and @mwd at @ weeks .',\n","  'line_number': 6,\n","  'total_lines': 11},\n"," {'target': 'RESULTS',\n","  'text': 'the mean difference between treatment arms ( @ % ci ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .',\n","  'line_number': 7,\n","  'total_lines': 11},\n"," {'target': 'RESULTS',\n","  'text': 'further , there was a clinically relevant reduction in the serum levels of il-@ , il-@ , tnf - , and hscrp at @ weeks in the intervention group when compared to the placebo group .',\n","  'line_number': 8,\n","  'total_lines': 11},\n"," {'target': 'RESULTS',\n","  'text': 'these differences remained significant at @ weeks .',\n","  'line_number': 9,\n","  'total_lines': 11},\n"," {'target': 'RESULTS',\n","  'text': 'the outcome measures in rheumatology clinical trials-osteoarthritis research society international responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .',\n","  'line_number': 10,\n","  'total_lines': 11},\n"," {'target': 'CONCLUSIONS',\n","  'text': 'low-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee oa ( clinicaltrials.gov identifier nct@ ) .',\n","  'line_number': 11,\n","  'total_lines': 11},\n"," {'target': 'BACKGROUND',\n","  'text': 'emotional eating is associated with overeating and the development of obesity .',\n","  'line_number': 0,\n","  'total_lines': 10},\n"," {'target': 'BACKGROUND',\n","  'text': 'yet , empirical evidence for individual ( trait ) differences in emotional eating and cognitive mechanisms that contribute to eating during sad mood remain equivocal .',\n","  'line_number': 1,\n","  'total_lines': 10}]"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["Fantastic! Looks like our `preprocess_text_with_line_numbers()` function worked great.\n","\n","How about we turn our list of dictionaries into pandas DataFrame so we visualize them better?"],"metadata":{"id":"jwbDl62dDT5Z"}},{"cell_type":"code","source":["import pandas as pd\n","\n","train_df = pd.DataFrame(train_samples)\n","val_df = pd.DataFrame(val_samples)\n","test_df = pd.DataFrame(test_samples)\n","train_df.head(14)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":488},"id":"GYdR-V3NDQUg","executionInfo":{"status":"ok","timestamp":1703583434409,"user_tz":-540,"elapsed":1518,"user":{"displayName":"Hee Seong Yang","userId":"11765788859671095501"}},"outputId":"fc6e7811-e484-4934-cc99-219674a48968"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["         target                                               text  \\\n","0     OBJECTIVE  to investigate the efficacy of @ weeks of dail...   \n","1       METHODS  a total of @ patients with primary knee oa wer...   \n","2       METHODS  outcome measures included pain reduction and i...   \n","3       METHODS  pain was assessed using the visual analog pain...   \n","4       METHODS  secondary outcome measures included the wester...   \n","5       METHODS  serum levels of interleukin @ ( il-@ ) , il-@ ...   \n","6       RESULTS  there was a clinically relevant reduction in t...   \n","7       RESULTS  the mean difference between treatment arms ( @...   \n","8       RESULTS  further , there was a clinically relevant redu...   \n","9       RESULTS  these differences remained significant at @ we...   \n","10      RESULTS  the outcome measures in rheumatology clinical ...   \n","11  CONCLUSIONS  low-dose oral prednisolone had both a short-te...   \n","12   BACKGROUND  emotional eating is associated with overeating...   \n","13   BACKGROUND  yet , empirical evidence for individual ( trai...   \n","\n","    line_number  total_lines  \n","0             0           11  \n","1             1           11  \n","2             2           11  \n","3             3           11  \n","4             4           11  \n","5             5           11  \n","6             6           11  \n","7             7           11  \n","8             8           11  \n","9             9           11  \n","10           10           11  \n","11           11           11  \n","12            0           10  \n","13            1           10  "],"text/html":["\n","  <div id=\"df-77984469-6a97-4031-850e-980ce9088384\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>target</th>\n","      <th>text</th>\n","      <th>line_number</th>\n","      <th>total_lines</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>OBJECTIVE</td>\n","      <td>to investigate the efficacy of @ weeks of dail...</td>\n","      <td>0</td>\n","      <td>11</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>METHODS</td>\n","      <td>a total of @ patients with primary knee oa wer...</td>\n","      <td>1</td>\n","      <td>11</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>METHODS</td>\n","      <td>outcome measures included pain reduction and i...</td>\n","      <td>2</td>\n","      <td>11</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>METHODS</td>\n","      <td>pain was assessed using the visual analog pain...</td>\n","      <td>3</td>\n","      <td>11</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>METHODS</td>\n","      <td>secondary outcome measures included the wester...</td>\n","      <td>4</td>\n","      <td>11</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>METHODS</td>\n","      <td>serum levels of interleukin @ ( il-@ ) , il-@ ...</td>\n","      <td>5</td>\n","      <td>11</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>RESULTS</td>\n","      <td>there was a clinically relevant reduction in t...</td>\n","      <td>6</td>\n","      <td>11</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>RESULTS</td>\n","      <td>the mean difference between treatment arms ( @...</td>\n","      <td>7</td>\n","      <td>11</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>RESULTS</td>\n","      <td>further , there was a clinically relevant redu...</td>\n","      <td>8</td>\n","      <td>11</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>RESULTS</td>\n","      <td>these differences remained significant at @ we...</td>\n","      <td>9</td>\n","      <td>11</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>RESULTS</td>\n","      <td>the outcome measures in rheumatology clinical ...</td>\n","      <td>10</td>\n","      <td>11</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>CONCLUSIONS</td>\n","      <td>low-dose oral prednisolone had both a short-te...</td>\n","      <td>11</td>\n","      <td>11</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>BACKGROUND</td>\n","      <td>emotional eating is associated with overeating...</td>\n","      <td>0</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>BACKGROUND</td>\n","      <td>yet , empirical evidence for individual ( trai...</td>\n","      <td>1</td>\n","      <td>10</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-77984469-6a97-4031-850e-980ce9088384')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-77984469-6a97-4031-850e-980ce9088384 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-77984469-6a97-4031-850e-980ce9088384');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-d2a16daa-c024-4abf-bd3a-e98728c4cdcd\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d2a16daa-c024-4abf-bd3a-e98728c4cdcd')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-d2a16daa-c024-4abf-bd3a-e98728c4cdcd button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","source":["Now our data is in DataFrame form, we can perform some data analysis on it."],"metadata":{"id":"rATEn3PsNsYY"}},{"cell_type":"code","source":["# Distribution of labels in training data\n","train_df.target.value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ejqdIi9RNag5","executionInfo":{"status":"ok","timestamp":1703583434410,"user_tz":-540,"elapsed":12,"user":{"displayName":"Hee Seong Yang","userId":"11765788859671095501"}},"outputId":"4d60883f-e4f5-443a-d69b-1446efc3766e"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["METHODS        59353\n","RESULTS        57953\n","CONCLUSIONS    27168\n","BACKGROUND     21727\n","OBJECTIVE      13839\n","Name: target, dtype: int64"]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":["Looks like sentences with the `OBJECTIVE` label are the least common.\n","\n","How about we check the distribution of our abstract lengths?"],"metadata":{"id":"7ee9UYvpN3bS"}},{"cell_type":"code","source":["train_df.total_lines.plot.hist();"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":431},"id":"lNfhPrsyN09w","executionInfo":{"status":"ok","timestamp":1703583435431,"user_tz":-540,"elapsed":1028,"user":{"displayName":"Hee Seong Yang","userId":"11765788859671095501"}},"outputId":"aaadce8a-56fb-4af2-d533-3a26ba2bdbad"},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":["Okay, looks like most of the abstracts are around 7 to 15 sentences in length.\n","\n","It's good to check these things out to make sure when we do train a model or test it on unseen samples, our results aren't outlandish."],"metadata":{"id":"81NwhRB3OAJX"}},{"cell_type":"markdown","source":["### Get lists of sentences\n","\n","When we build our deep learning model, one of its main inputs will be a list of strings (the lines of an abstract).\n","\n","We can get these easily from our DataFrames by calling the `tolist()` method on our `\"text\"` columns."],"metadata":{"id":"y_rgRxFSOGDQ"}},{"cell_type":"code","source":["# Convert abstract text lines into lists\n","train_sentences = train_df['text'].tolist()\n","val_sentences = val_df['text'].tolist()\n","test_sentences = test_df['text'].tolist()\n","len(train_sentences), len(val_sentences), len(test_sentences)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LwGjD3nhN81g","executionInfo":{"status":"ok","timestamp":1703583435432,"user_tz":-540,"elapsed":20,"user":{"displayName":"Hee Seong Yang","userId":"11765788859671095501"}},"outputId":"5bce299a-841d-44e0-f2f5-110173f5cb87"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(180040, 30212, 30135)"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["# View first 10 lines of training sentences\n","train_sentences[:10]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wX1HcIQXOaIv","executionInfo":{"status":"ok","timestamp":1703583435433,"user_tz":-540,"elapsed":15,"user":{"displayName":"Hee Seong Yang","userId":"11765788859671095501"}},"outputId":"7b5fdf6e-2b3b-42da-b565-25514039a95d"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n"," 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n"," 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n"," 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n"," 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .',\n"," 'serum levels of interleukin @ ( il-@ ) , il-@ , tumor necrosis factor ( tnf ) - , and high-sensitivity c-reactive protein ( hscrp ) were measured .',\n"," 'there was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , pga , and @mwd at @ weeks .',\n"," 'the mean difference between treatment arms ( @ % ci ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .',\n"," 'further , there was a clinically relevant reduction in the serum levels of il-@ , il-@ , tnf - , and hscrp at @ weeks in the intervention group when compared to the placebo group .',\n"," 'these differences remained significant at @ weeks .']"]},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","source":["Alright, we've separated our text samples. As you might've guessed, we'll have to write code to convert the text to numbers before we can use it with our machine-learning models, we'll get to this soon."],"metadata":{"id":"asIC_i_RQNld"}},{"cell_type":"markdown","source":["## Make numeric labels (ML models require numeric labels)\n","\n","We're going to create one hot and label encoded labels.\n","\n","We could get away with just making label-encoded labels, however, TensorFlow's `CategoricalCrossentropy` loss function likes to have one hot encoded labels (this will enable us to use label smoothing later on).\n","\n","To numerically encode labels we'll use Scikit-Learn's [`OneHotEncoder`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) and [`LabelEncoder`](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html) classes."],"metadata":{"id":"cPoU-1rUQSym"}},{"cell_type":"code","source":["# One hot encode labels\n","from sklearn.preprocessing import OneHotEncoder\n","\n","one_hot_encoder = OneHotEncoder(sparse_output=False)\n","train_labels_one_hot = one_hot_encoder.fit_transform(train_df['target'].to_numpy().reshape(-1, 1))\n","val_labels_one_hot = one_hot_encoder.transform(val_df[\"target\"].to_numpy().reshape(-1, 1))\n","test_labels_one_hot = one_hot_encoder.transform(test_df[\"target\"].to_numpy().reshape(-1, 1))\n","\n","# Check what training labels look like\n","train_labels_one_hot"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yhhq35RAOeaP","executionInfo":{"status":"ok","timestamp":1703583437597,"user_tz":-540,"elapsed":2176,"user":{"displayName":"Hee Seong Yang","userId":"11765788859671095501"}},"outputId":"9c26186a-3c60-446d-daf4-a81d1feb352f"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0., 0., 0., 1., 0.],\n","       [0., 0., 1., 0., 0.],\n","       [0., 0., 1., 0., 0.],\n","       ...,\n","       [0., 0., 0., 0., 1.],\n","       [0., 1., 0., 0., 0.],\n","       [0., 1., 0., 0., 0.]])"]},"metadata":{},"execution_count":16}]},{"cell_type":"markdown","source":["### Label encode labels"],"metadata":{"id":"dvFUFuZbRB4p"}},{"cell_type":"code","source":["# Extract labels (\"target\" columns) and encode them into integers\n","from sklearn.preprocessing import LabelEncoder\n","\n","label_encoder = LabelEncoder()\n","train_labels_encoded = label_encoder.fit_transform(train_df['target'].to_numpy())\n","val_labels_encoded = label_encoder.transform(val_df[\"target\"].to_numpy())\n","test_labels_encoded = label_encoder.transform(test_df[\"target\"].to_numpy())\n","\n","# Check what training labels look like\n","train_labels_encoded"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xoqp-72jQ_lH","executionInfo":{"status":"ok","timestamp":1703583438153,"user_tz":-540,"elapsed":559,"user":{"displayName":"Hee Seong Yang","userId":"11765788859671095501"}},"outputId":"6d57e9f5-a30b-4194-f0f8-78d2834773eb"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([3, 2, 2, ..., 4, 1, 1])"]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","source":["Now we've trained an instance of `LabelEncoder`, we can get the class names and the number of classes using the `classes_` attribute."],"metadata":{"id":"PeL44v3mRRFg"}},{"cell_type":"code","source":["# Get class names and number of classes from LabelEncoder instance\n","num_classes = len(label_encoder.classes_)\n","class_names = label_encoder.classes_\n","num_classes, class_names"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sXJa1MJvRPwX","executionInfo":{"status":"ok","timestamp":1703583438153,"user_tz":-540,"elapsed":8,"user":{"displayName":"Hee Seong Yang","userId":"11765788859671095501"}},"outputId":"b55914cd-1cec-4b3c-ae85-177caa5befd2"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(5,\n"," array(['BACKGROUND', 'CONCLUSIONS', 'METHODS', 'OBJECTIVE', 'RESULTS'],\n","       dtype=object))"]},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","source":["## Creating a series of model experiments\n","\n","We've preprocessed our data so now, in true machine-learning fashion, it's time to set up a series of modeling experiments.\n","\n","We'll start by creating a simple baseline model to obtain a score we'll try to beat by building more and more complex models as we move towards replicating the sequence model outlined in [*Neural networks for joint sentence classification in medical paper abstracts*](https://arxiv.org/pdf/1612.05251.pdf).\n","\n","For each model, we'll train it on the training data and evaluate it on the validation data."],"metadata":{"id":"BfmtAIr_Rvk2"}},{"cell_type":"markdown","source":["## Model 0: Getting a baseline\n","\n","Our first model will be a TF-IDF Multinomial Naive Bayes as recommended by [Scikit-Learn's machine learning map](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html).\n","\n","To build it, we'll create a Scikit-Learn `Pipeline` which uses the [`TfidfVectorizer`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) class to convert our abstract sentences to numbers using the TF-IDF (term frequency-inverse document frequency) algorithm and then learns to classify our sentences using the [`MultinomialNB`](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html) algorithm."],"metadata":{"id":"u7SQ4Vm5SB_V"}},{"cell_type":"code","source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.pipeline import Pipeline\n","\n","# Create a pipeline\n","model_0 = Pipeline([\n","    ('tf-idf', TfidfVectorizer()),\n","    ('clf', MultinomialNB())\n","])\n","\n","# Fit the pipeline to the training data\n","model_0.fit(X=train_sentences,\n","            y=train_labels_encoded)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":125},"id":"hHHp1FjzRsR3","executionInfo":{"status":"ok","timestamp":1703583446260,"user_tz":-540,"elapsed":8111,"user":{"displayName":"Hee Seong Yang","userId":"11765788859671095501"}},"outputId":"32309f43-3071-4cc5-8dab-faf9c8c4cf38"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Pipeline(steps=[('tf-idf', TfidfVectorizer()), ('clf', MultinomialNB())])"],"text/html":["<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tf-idf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tf-idf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"]},"metadata":{},"execution_count":19}]},{"cell_type":"markdown","source":["Due to the speed of the Multinomial Naive Bayes algorithm, it trains very quickly.\n","\n","We can evaluate our model's accuracy on the validation dataset using the `score()` method."],"metadata":{"id":"e1f_8ykYwI-K"}},{"cell_type":"code","source":["# Evaluate baseline on validation dataset\n","model_0.score(X=val_sentences,\n","              y=val_labels_encoded)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nymaIH-6S6YG","executionInfo":{"status":"ok","timestamp":1703583447577,"user_tz":-540,"elapsed":1352,"user":{"displayName":"Hee Seong Yang","userId":"11765788859671095501"}},"outputId":"ac81e1dc-3339-4307-dff4-78c846bd6a51"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.7218323844829869"]},"metadata":{},"execution_count":20}]},{"cell_type":"markdown","source":["Nice! Looks like 72.1% accuracy will be the number to beat with our deeper models.\n","\n","Now let's make some predictions with our baseline model to further evaluate it."],"metadata":{"id":"XUCJNjyCwY0F"}},{"cell_type":"code","source":["# Make prediction\n","baseline_preds = model_0.predict(val_sentences)\n","baseline_preds"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ca1TDqMIwWAb","executionInfo":{"status":"ok","timestamp":1703583448112,"user_tz":-540,"elapsed":558,"user":{"displayName":"Hee Seong Yang","userId":"11765788859671095501"}},"outputId":"9609ef57-fa38-4e92-a282-bea0f90c3bb0"},"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([4, 1, 3, ..., 4, 4, 1])"]},"metadata":{},"execution_count":21}]},{"cell_type":"markdown","source":["To evaluate our baseline's predictions, we'll import the `calculate_results()` function we created in the [previous notebook](https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/08_introduction_to_nlp_in_tensorflow.ipynb) and added it to our [`helper_functions.py` script](https://github.com/yhs2773/TensorFlow-for-Deep-Learning/blob/main/helper_functions.py) to compare them to the ground truth labels.\n","\n","More specificially the `calculate_results()` function will help us obtain the following:\n","\n","- Accuracy\n","- Precision\n","- Recall\n","- F1-score"],"metadata":{"id":"Blqk15dIwnv-"}},{"cell_type":"markdown","source":["### Download helper functions script\n","\n","Let's get our `helper_functions.py` script we've been using to store helper functions we've created in previous notebooks."],"metadata":{"id":"4xTnEWxoxG5z"}},{"cell_type":"code","source":["# Download helper functions script\n","!wget https://raw.githubusercontent.com/yhs2773/TensorFlow-for-Deep-Learning/main/helper_functions.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8y1bYPjywldC","executionInfo":{"status":"ok","timestamp":1703583448585,"user_tz":-540,"elapsed":478,"user":{"displayName":"Hee Seong Yang","userId":"11765788859671095501"}},"outputId":"d4fa8005-47f9-497b-a714-3bd4c066c38e"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-12-26 09:37:26--  https://raw.githubusercontent.com/yhs2773/TensorFlow-for-Deep-Learning/main/helper_functions.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 11093 (11K) [text/plain]\n","Saving to: â€˜helper_functions.pyâ€™\n","\n","\rhelper_functions.py   0%[                    ]       0  --.-KB/s               \rhelper_functions.py 100%[===================>]  10.83K  --.-KB/s    in 0s      \n","\n","2023-12-26 09:37:26 (105 MB/s) - â€˜helper_functions.pyâ€™ saved [11093/11093]\n","\n"]}]},{"cell_type":"markdown","source":["Now we've got the helper functions script we can import the `caculate_results()` function and see how our baseline model went."],"metadata":{"id":"6FLKoEuaxMjG"}},{"cell_type":"code","source":["# Import calculate_results helper function\n","from helper_functions import calculate_results"],"metadata":{"id":"ubsPP9OnxBik","executionInfo":{"status":"ok","timestamp":1703583453731,"user_tz":-540,"elapsed":5150,"user":{"displayName":"Hee Seong Yang","userId":"11765788859671095501"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["# Calculate baseline results\n","baseline_results = calculate_results(y_true=val_labels_encoded,\n","                                     y_pred=baseline_preds)\n","\n","baseline_results"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZrItJ9Y5xUOD","executionInfo":{"status":"ok","timestamp":1703583453732,"user_tz":-540,"elapsed":18,"user":{"displayName":"Hee Seong Yang","userId":"11765788859671095501"}},"outputId":"c00ec70b-e270-4449-a677-6db3249370c7"},"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'accuracy': 72.1832384482987,\n"," 'precision': 0.7186466952323352,\n"," 'recall': 0.7218323844829869,\n"," 'f1': 0.6989250353450294}"]},"metadata":{},"execution_count":24}]},{"cell_type":"markdown","source":["## Preparing our data for deep sequence models\n","\n","Excellent! We've got a working baseline to try and improve upon.\n","\n","But before we start building deeper models, we've got to create vectorization and embedding layers.\n","\n","The vectorization layer will convert our text to numbers and the embedding layer will capture the relationships between those numbers.\n","\n","To start creating our vectorization and embedding layers, we'll need to import the appropriate libraries (namely TensorFlow and NumPy)."],"metadata":{"id":"WJp8X0NexeeK"}},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras import layers"],"metadata":{"id":"ppvUXgm3xZGc","executionInfo":{"status":"ok","timestamp":1703583453733,"user_tz":-540,"elapsed":9,"user":{"displayName":"Hee Seong Yang","userId":"11765788859671095501"}}},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":["Since we'll be turning our sentences into numbers, it's a good idea to figure out how many words are in each sentence.\n","\n","When our model goes through our sentences, it works best when they're all the same length (this is important for creating batches of the same size tensors).\n","\n","For example, if one sentence is eight words long and another is 29 words long, we want to pad the eight-word sentence with zeros so it ends up being the same length as the 29-word sentence.\n","\n","Let's write some code to find the average length of sentences in the training set."],"metadata":{"id":"vWBEO9d-xtcI"}},{"cell_type":"code","source":["# How long is each sentence on average?\n","sent_lens = [len(sentence.split()) for sentence in train_sentences]\n","avg_sent_len = np.mean(sent_lens)\n","avg_sent_len # return average sentence length (in tokens)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y8t37BZoxszq","executionInfo":{"status":"ok","timestamp":1703583454249,"user_tz":-540,"elapsed":525,"user":{"displayName":"Hee Seong Yang","userId":"11765788859671095501"}},"outputId":"da511c2b-8c77-4152-c81d-1cacf52036f0"},"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["26.338269273494777"]},"metadata":{},"execution_count":26}]},{"cell_type":"markdown","source":["How about the distribution of sentence lengths?"],"metadata":{"id":"aeZHbmWeyH2B"}},{"cell_type":"code","source":["# What does the distribution look like?\n","import matplotlib.pyplot as plt\n","\n","plt.hist(sent_lens, bins=7);"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":430},"id":"esW5XKtoyGQi","executionInfo":{"status":"ok","timestamp":1703583455540,"user_tz":-540,"elapsed":1296,"user":{"displayName":"Hee Seong Yang","userId":"11765788859671095501"}},"outputId":"2b877aab-86d0-43e0-aab3-fd39d6d8e2d1"},"execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":["Looks like the vast majority of sentences are between 0 and 50 tokens in length.\n","\n","We can use NumPy's [`percentile`](https://numpy.org/doc/stable/reference/generated/numpy.percentile.html) to find the value which covers 95% of the sentence lengths."],"metadata":{"id":"jTJawAhgyukp"}},{"cell_type":"code","source":["# How long of a sentence covers 95% of the lengths?\n","output_seq_len = int(np.percentile(sent_lens, 95))\n","output_seq_len"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XV1rYdStyoYK","executionInfo":{"status":"ok","timestamp":1703583455541,"user_tz":-540,"elapsed":18,"user":{"displayName":"Hee Seong Yang","userId":"11765788859671095501"}},"outputId":"87084705-bde0-4e3c-f621-2c9b8f57bedb"},"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["55"]},"metadata":{},"execution_count":28}]},{"cell_type":"markdown","source":["Wonderful! It looks like 95% of the sentences in our training set have a length of 55 tokens or less.\n","\n","When we create our tokenization layer, we'll use this value to turn all of our sentences into the same length. Meaning sentences with a length below 55 get padded with zeros and sentences with a length above 55 get truncated (words after 55 get cut off).\n","\n","> ðŸ¤” Question: Why 95%?\n","\n","We could use the max sentence length of the sentences in the training set."],"metadata":{"id":"X4x1p-21zCoL"}},{"cell_type":"code","source":["# Maximum sentence length in the training set\n","max(sent_lens)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NZw_1IpJy9Ia","executionInfo":{"status":"ok","timestamp":1703583455541,"user_tz":-540,"elapsed":15,"user":{"displayName":"Hee Seong Yang","userId":"11765788859671095501"}},"outputId":"6769f380-7192-4c7c-bbe6-52ee935c516a"},"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["296"]},"metadata":{},"execution_count":29}]},{"cell_type":"markdown","source":["However, since hardly any sentences even come close to the max length, it would mean the majority of the data we pass to our model would be zeros (since all sentences below the max length would get padded with zeros).\n","\n","ðŸ”‘ Note: The steps we've gone through are good practice when working with a text corpus for an NLP problem. You want to know how long your samples are and what the distribution of them is. See section 4 Data Analysis of the [PubMed 200k RCT paper](https://arxiv.org/pdf/1710.06071.pdf) for further examples."],"metadata":{"id":"6Gh4hgZHzQD7"}},{"cell_type":"markdown","source":["### Create text vectorizer\n","\n","Now we've got a little more information about our texts, let's create a way to turn them into numbers.\n","\n","To do so, we'll use the [`TextVectorization`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/TextVectorization) layer from TensorFlow.\n","\n","We'll keep all the parameters default except for `max_tokens` (the number of unique words in our dataset) and `output_sequence_length` (our desired output length for each vectorized sentence).\n","\n","Section 3.2 of the [PubMed 200k RCT paper](https://arxiv.org/pdf/1710.06071.pdf) states the vocabulary size of the PubMed 20k dataset as 68,000. So we'll use that as our `max_tokens` parameter."],"metadata":{"id":"FUnwdWacze4C"}},{"cell_type":"code","source":["# How many words are in our vocabulary? (taken from 3.2 in https://arxiv.org/pdf/1710.06071.pdf)\n","max_tokens = 68000"],"metadata":{"id":"EJoJ6w5gzOiC","executionInfo":{"status":"ok","timestamp":1703583455542,"user_tz":-540,"elapsed":14,"user":{"displayName":"Hee Seong Yang","userId":"11765788859671095501"}}},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":["And since discovered a sentence length of 55 covers 95% of the training sentences, we'll use that as our `output_sequence_length` parameter."],"metadata":{"id":"W--nsHxN0BWv"}},{"cell_type":"code","source":["# Create text vectorizer\n","\n","# After TensorFlow 2.6\n","from tensorflow.keras.layers import TextVectorization\n","\n","# # Before TensorFlow 2.6\n","# from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n","\n","text_vectorizer = TextVectorization(max_tokens=max_tokens,      # number of words in vocabulary\n","                                    output_sequence_length=55)  # desired output length of vectorized sequences"],"metadata":{"id":"Qwc8kHLw0AWC","executionInfo":{"status":"ok","timestamp":1703583456607,"user_tz":-540,"elapsed":1079,"user":{"displayName":"Hee Seong Yang","userId":"11765788859671095501"}}},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":["Great! Looks like our `text_vectorizer` is ready, let's adapt it to the training data (let it read the training data and figure out what number should represent what word) and then test it out."],"metadata":{"id":"0tY53LpH0lxp"}},{"cell_type":"code","source":["# Adapt text vectorizer to training sentences\n","text_vectorizer.adapt(train_sentences)"],"metadata":{"id":"xf1MQhsh0kK5","executionInfo":{"status":"ok","timestamp":1703583479644,"user_tz":-540,"elapsed":23043,"user":{"displayName":"Hee Seong Yang","userId":"11765788859671095501"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["# Test out text vectorizer\n","import random\n","\n","target_sentence = random.choice(train_sentences)\n","print(f\"Text:\\n{target_sentence}\")\n","print(f\"\\nLength of text: {len(target_sentence.split())}\")\n","print(f\"\\nVectorized text:\\n{text_vectorizer([target_sentence])}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EjkGLflv0tj7","executionInfo":{"status":"ok","timestamp":1703583480749,"user_tz":-540,"elapsed":1116,"user":{"displayName":"Hee Seong Yang","userId":"11765788859671095501"}},"outputId":"2a586a75-7cba-4a4f-f994-6662e206e84d"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["Text:\n","a total of @ men were diagnosed with pc , @ ( @ % ) in the screening arm and @ ( @ % ) in the control arm ( p < @ ) .\n","\n","Length of text: 35\n","\n","Vectorized text:\n","[[   8   76    4  309    9  767    7 1884    5    2  387  207    3    5\n","     2   35  207   14    0    0    0    0    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0    0    0]]\n"]}]},{"cell_type":"markdown","source":["Cool, we've now got a way to turn our sequences into numbers.\n","\n","> ðŸ›  Exercise: Try running the cell above a dozen or so times. What do you notice about sequences with a length less than 55?\n",">\n","> Any sequences with a length less than 55 will have 0s added at the back until the length reaches to 55\n","\n","Using the [`get_vocabulary()`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/TextVectorization) method of our `text_vectorizer` we can find out a few different tidbits about our text."],"metadata":{"id":"8__Zt04102gC"}},{"cell_type":"code","source":["# How many words in our training vocabulary?\n","rct_20k_text_vocab = text_vectorizer.get_vocabulary()\n","print(f\"Number of words in vocabulary: {len(rct_20k_text_vocab)}\"),\n","print(f\"Most common words in the vocabulary: {rct_20k_text_vocab[:5]}\")\n","print(f\"Least common words in the vocabulary: {rct_20k_text_vocab[-5:]}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iedSWdBO008R","executionInfo":{"status":"ok","timestamp":1703583481266,"user_tz":-540,"elapsed":522,"user":{"displayName":"Hee Seong Yang","userId":"11765788859671095501"}},"outputId":"f5bccc43-bc02-4248-cb34-b2be052a00be"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of words in vocabulary: 64841\n","Most common words in the vocabulary: ['', '[UNK]', 'the', 'and', 'of']\n","Least common words in the vocabulary: ['aainduced', 'aaigroup', 'aachener', 'aachen', 'aaacp']\n"]}]},{"cell_type":"markdown","source":["And if we want to figure out the configuration of our `text_vectorizer` we can use the `get_config()` method."],"metadata":{"id":"UMBASZdl1jrk"}},{"cell_type":"code","source":["# Get the config of our text vectorizer\n","text_vectorizer.get_config()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TqKbnHZl1hFp","executionInfo":{"status":"ok","timestamp":1703583481266,"user_tz":-540,"elapsed":20,"user":{"displayName":"Hee Seong Yang","userId":"11765788859671095501"}},"outputId":"87590638-fd81-4f26-8316-ec9e66602090"},"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'name': 'text_vectorization',\n"," 'trainable': True,\n"," 'dtype': 'string',\n"," 'batch_input_shape': (None,),\n"," 'max_tokens': 68000,\n"," 'standardize': 'lower_and_strip_punctuation',\n"," 'split': 'whitespace',\n"," 'ngrams': None,\n"," 'output_mode': 'int',\n"," 'output_sequence_length': 55,\n"," 'pad_to_max_tokens': False,\n"," 'sparse': False,\n"," 'ragged': False,\n"," 'vocabulary': None,\n"," 'idf_weights': None,\n"," 'encoding': 'utf-8',\n"," 'vocabulary_size': 64841}"]},"metadata":{},"execution_count":35}]},{"cell_type":"markdown","source":["### Create custom text embedding\n","\n","Our `token_vectorization` layer maps the words in our text directly to numbers. However, this doesn't necessarily capture the relationships between those numbers.\n","\n","To create a richer numerical representation of our text, we can use an **embedding**.\n","\n","As our model learns (by going through many different examples of abstract sentences and their labels), it'll update its embedding to better represent the relationships between tokens in our corpus.\n","\n","We can create a trainable embedding layer using TensorFlow's [`Embedding`](https://www.tensorflow.org/tutorials/text/word_embeddings) layer.\n","\n","Once again, the main parameters we're concerned with here are the inputs and outputs of our `Embedding` layer.\n","\n","The `input_dim` parameter defines the size of our vocabulary. And the `output_dim` parameter defines the dimension of the embedding output.\n","\n","Once created, our embedding layer will take the integer outputs of our `text_vectorization` layer as inputs and convert them to feature vectors of size `output_dim`.\n","\n","Let's see it in action."],"metadata":{"id":"k21ynfj513Wb"}},{"cell_type":"code","source":["# Create token embedding layer\n","token_embed = layers.Embedding(input_dim=len(rct_20k_text_vocab),   # length of vocabulary\n","                               output_dim=128,                      # Note: different embedding sizes result in drastically different numbers of parameters to train\n","                               # Use masking to handle variable sequence lengths (save space)\n","                               mask_zero=True,\n","                               name='token_embedding')\n","\n","# Show example embedding\n","print(f\"Sentence before vectorization:\\n{target_sentence}\\n\")\n","vectorized_sentence = text_vectorizer([target_sentence])\n","print(f\"Sentence after vectorization (before embedding):\\n{vectorized_sentence}\\n\")\n","embedded_sentence = token_embed(vectorized_sentence)\n","print(f\"Sentence after embedding:\\n{embedded_sentence}\\n\")\n","print(f\"Embedded sentence shape: {embedded_sentence.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-A5wQau11rah","executionInfo":{"status":"ok","timestamp":1703583481266,"user_tz":-540,"elapsed":15,"user":{"displayName":"Hee Seong Yang","userId":"11765788859671095501"}},"outputId":"a4401722-578b-4a5d-9add-c75d6f395a2a"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["Sentence before vectorization:\n","a total of @ men were diagnosed with pc , @ ( @ % ) in the screening arm and @ ( @ % ) in the control arm ( p < @ ) .\n","\n","Sentence after vectorization (before embedding):\n","[[   8   76    4  309    9  767    7 1884    5    2  387  207    3    5\n","     2   35  207   14    0    0    0    0    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0    0    0]]\n","\n","Sentence after embedding:\n","[[[ 0.02082064 -0.04286784 -0.00791369 ... -0.03887355  0.00955077\n","   -0.00653077]\n","  [ 0.03158945  0.02961243 -0.04637737 ... -0.03491436  0.02778361\n","    0.01289879]\n","  [-0.00258392 -0.04586997 -0.04768888 ...  0.00191813 -0.00989051\n","    0.03215918]\n","  ...\n","  [-0.03520219  0.02357982 -0.0015862  ...  0.00638407  0.01492986\n","   -0.00445458]\n","  [-0.03520219  0.02357982 -0.0015862  ...  0.00638407  0.01492986\n","   -0.00445458]\n","  [-0.03520219  0.02357982 -0.0015862  ...  0.00638407  0.01492986\n","   -0.00445458]]]\n","\n","Embedded sentence shape: (1, 55, 128)\n"]}]},{"cell_type":"markdown","source":["## Create datasets (as fast as possible)\n","\n","We've gone through all the trouble of preprocessing our datasets to be used with a machine-learning model, however, there are still a few steps we can use to make them work faster with our models.\n","\n","Namely, the tf.data API provides methods that enable faster data loading.\n","\n","> ðŸ“– Resource: For best practices on data loading in TensorFlow, check out the following:\n",">\n","> - [tf.data: Build TensorFlow input pipelines](https://www.tensorflow.org/guide/data)\n","> - [Better performance with the tf.data API](https://www.tensorflow.org/guide/data_performance)\n","\n","The main step we'll want to use with our data is to turn it into a `PrefetchDataset` of batches.\n","\n","Doing so we'll ensure TensorFlow loads our data onto the GPU as fast as possible, in turn leading to faster training time.\n","\n","To create a batched `PrefetchDataset` we can use the methods [`batch()`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#batch) and [`prefetch()`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#prefetch), the parameter [`tf.data.AUTOTUNE`](https://www.tensorflow.org/api_docs/python/tf/data#AUTOTUNE) will also allow TensorFlow to determine the optimal amount of compute to use to prepare datasets."],"metadata":{"id":"9JlaBTVP6d8E"}},{"cell_type":"code","source":["# Turn our data into TensorFlow Datasets\n","train_dataset = tf.data.Dataset.from_tensor_slices((train_sentences, train_labels_one_hot))\n","valid_dataset = tf.data.Dataset.from_tensor_slices((val_sentences, val_labels_one_hot))\n","test_dataset = tf.data.Dataset.from_tensor_slices((test_sentences, test_labels_one_hot))\n","\n","train_dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pLfxNk_44moC","executionInfo":{"status":"ok","timestamp":1703583481704,"user_tz":-540,"elapsed":449,"user":{"displayName":"Hee Seong Yang","userId":"11765788859671095501"}},"outputId":"2c623cec-ad0f-4525-c77c-10409d55e045"},"execution_count":37,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<_TensorSliceDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(5,), dtype=tf.float64, name=None))>"]},"metadata":{},"execution_count":37}]},{"cell_type":"code","source":["# Take the TensorSliceDatasets and turn them into prefetches batches\n","train_dataset = train_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n","valid_dataset = valid_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n","test_dataset = test_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n","\n","train_dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eaxPIvWo8FRb","executionInfo":{"status":"ok","timestamp":1703583481705,"user_tz":-540,"elapsed":17,"user":{"displayName":"Hee Seong Yang","userId":"11765788859671095501"}},"outputId":"ffb4bc74-6a6e-41ba-be30-4c01c159b16a"},"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<_PrefetchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None, 5), dtype=tf.float64, name=None))>"]},"metadata":{},"execution_count":38}]},{"cell_type":"markdown","source":["## Model 1: Conv1D with token embeddings\n","\n","Alright, we've now got a way to numerically represent our text and labels, time to build a series of deep models to try and improve upon our baseline.\n","\n","All of our deep models will follow a similar structure:\n","```\n","Input (text) -> Tokenize -> Embedding -> Layers -> Output (label probability)\n","```\n","The main component we'll be changing throughout is the `Layers` component. Because any modern deep NLP model requires text to be converted into an embedding before meaningful patterns can be discovered within.\n","\n","The first model we're going to build is a 1-dimensional Convolutional Neural Network.\n","\n","We're also going to be following the standard machine learning workflow of:\n","\n","- Build model\n","- Train model\n","- Evaluate model (make predictions and compare to ground truth)"],"metadata":{"id":"X4V2BX1C8WI7"}},{"cell_type":"code","source":["# Create 1D convolutional model to process sequences\n","inputs = layers.Input(shape=(1,), dtype=tf.string)\n","text_vectors = text_vectorizer(inputs)          # vectorize text inputs\n","token_embeddings = token_embed(text_vectors)    # create embedding\n","x = layers.Conv1D(filters=64, kernel_size=5, padding='same', activation='relu')(token_embeddings)\n","x = layers.GlobalAveragePooling1D()(x)          # condense the output of our feature vector\n","outputs = layers.Dense(num_classes, activation='softmax')(x)\n","model_1 = tf.keras.Model(inputs=inputs, outputs=outputs)\n","\n","# Compile\n","model_1.compile(optimizer=tf.keras.optimizers.Adam(),\n","                # if your labels are integer form (not one hot) use sparse_categorical_crossentropy\n","                loss='categorical_crossentropy',\n","                metrics=['accuracy'])"],"metadata":{"id":"lWzfxe2H8TTr","executionInfo":{"status":"ok","timestamp":1703583481705,"user_tz":-540,"elapsed":14,"user":{"displayName":"Hee Seong Yang","userId":"11765788859671095501"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["# Get summary of Conv1D model\n","model_1.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PFUZtuZO9VJK","executionInfo":{"status":"ok","timestamp":1703583482213,"user_tz":-540,"elapsed":521,"user":{"displayName":"Hee Seong Yang","userId":"11765788859671095501"}},"outputId":"e2427b57-8ed1-45ff-f2c2-7562c9b03c08"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 1)]               0         \n","                                                                 \n"," text_vectorization (TextVe  (None, 55)                0         \n"," ctorization)                                                    \n","                                                                 \n"," token_embedding (Embedding  (None, 55, 128)           8299648   \n"," )                                                               \n","                                                                 \n"," conv1d (Conv1D)             (None, 55, 64)            41024     \n","                                                                 \n"," global_average_pooling1d (  (None, 64)                0         \n"," GlobalAveragePooling1D)                                         \n","                                                                 \n"," dense (Dense)               (None, 5)                 325       \n","                                                                 \n","=================================================================\n","Total params: 8340997 (31.82 MB)\n","Trainable params: 8340997 (31.82 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["Wonderful! We've got our first deep sequence model built and ready to go.\n","\n","Checking out the model summary, you'll notice the majority of the trainable parameters are within the embedding layer. If we were to increase the size of the embedding (by increasing the `output_dim` parameter of the `Embedding` layer), the number of trainable parameters would increase dramatically.\n","\n","It's time to fit our model to the training data but we're going to make a mindful change.\n","\n","Since our training data contains nearly 200,000 sentences, fitting a deep model may take a while even with a GPU. So to keep our experiments swift, we're going to run them on a subset of the training dataset.\n","\n","More specifically, we'll only use the first 10% of batches (about 18,000 samples) of the training set to train on and the first 10% of batches from the validation set to validate on.\n","\n","> ðŸ”‘ Note: It's a standard practice in machine learning to test your models on smaller subsets of data first to make sure they work before scaling them to larger amounts of data. You should aim to run many smaller experiments rather than only a handful of large experiments. And since your time is limited, one of the best ways to run smaller experiments is to reduce the amount of data you're working with (10% of the full dataset is usually a good amount, as long as it covers a similar distribution)."],"metadata":{"id":"vKK2V1-d9hXQ"}},{"cell_type":"code","source":["# Fit the model\n","model_1_history = model_1.fit(train_dataset,\n","                              steps_per_epoch=int(len(train_dataset) * 0.1),    # only fit on 10% of batches for faster training time\n","                              epochs=3,\n","                              validation_data=valid_dataset,\n","                              validation_steps=int(len(valid_dataset) * 0.1))   # only validate on 10% of batches"],"metadata":{"id":"gDbGqHMP9W5S","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1703583523712,"user_tz":-540,"elapsed":41514,"user":{"displayName":"Hee Seong Yang","userId":"11765788859671095501"}},"outputId":"ccc86a31-b4e8-40e8-aff8-38ebbd2f88b1"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/3\n","562/562 [==============================] - 21s 32ms/step - loss: 0.9194 - accuracy: 0.6357 - val_loss: 0.6860 - val_accuracy: 0.7360\n","Epoch 2/3\n","562/562 [==============================] - 5s 9ms/step - loss: 0.6574 - accuracy: 0.7563 - val_loss: 0.6300 - val_accuracy: 0.7719\n","Epoch 3/3\n","562/562 [==============================] - 4s 7ms/step - loss: 0.6171 - accuracy: 0.7762 - val_loss: 0.5978 - val_accuracy: 0.7779\n"]}]},{"cell_type":"markdown","source":["Brilliant! We've got our first trained deep sequence model, and it didn't take too long (and if we didn't prefetch our batched data, it would've taken longer).\n","\n","It is time to make some predictions with our model and then evaluate them."],"metadata":{"id":"DwhDpiileuDi"}},{"cell_type":"code","source":["# Evaluate on whole validation dataset (we only validated on 10% of batches during training)\n","model_1.evaluate(valid_dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zNCeYC8Be2M9","executionInfo":{"status":"ok","timestamp":1703583528476,"user_tz":-540,"elapsed":4795,"user":{"displayName":"Hee Seong Yang","userId":"11765788859671095501"}},"outputId":"3143b758-8fba-4d8f-9576-9ff8c7401493"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["945/945 [==============================] - 4s 4ms/step - loss: 0.6000 - accuracy: 0.7851\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.5999988913536072, 0.7850853800773621]"]},"metadata":{},"execution_count":42}]},{"cell_type":"code","source":["# Make predictions (our model outputs prediction probabilities for each class)\n","model_1_pred_probs = model_1.predict(valid_dataset)\n","model_1_pred_probs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lAdgaa8_e_U5","executionInfo":{"status":"ok","timestamp":1703583531344,"user_tz":-540,"elapsed":2883,"user":{"displayName":"Hee Seong Yang","userId":"11765788859671095501"}},"outputId":"14a11ef5-ff20-469a-9f36-af93026764fa"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["945/945 [==============================] - 2s 2ms/step\n"]},{"output_type":"execute_result","data":{"text/plain":["array([[4.3139687e-01, 1.6420211e-01, 8.4289424e-02, 2.8985029e-01,\n","        3.0261299e-02],\n","       [4.2347842e-01, 2.8782082e-01, 1.1396490e-02, 2.6899821e-01,\n","        8.3061205e-03],\n","       [1.3277619e-01, 9.7453641e-03, 1.8299327e-03, 8.5560501e-01,\n","        4.3512260e-05],\n","       ...,\n","       [4.0869163e-06, 5.8759877e-04, 5.9702038e-04, 1.8534307e-06,\n","        9.9880946e-01],\n","       [5.8114517e-02, 4.4911397e-01, 1.0290945e-01, 6.5543339e-02,\n","        3.2431880e-01],\n","       [1.6791469e-01, 6.7179298e-01, 3.9874088e-02, 4.8522219e-02,\n","        7.1896061e-02]], dtype=float32)"]},"metadata":{},"execution_count":43}]},{"cell_type":"code","source":["# Convert pred probs to classes\n","model_1_preds = tf.argmax(model_1_pred_probs, axis=1)\n","model_1_preds"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gtTH0i6IfDD6","executionInfo":{"status":"ok","timestamp":1703583531345,"user_tz":-540,"elapsed":11,"user":{"displayName":"Hee Seong Yang","userId":"11765788859671095501"}},"outputId":"7b626132-ac98-44da-aaea-93d4fe73563c"},"execution_count":44,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(30212,), dtype=int64, numpy=array([0, 0, 3, ..., 4, 1, 1])>"]},"metadata":{},"execution_count":44}]},{"cell_type":"code","source":["# Calculate model_1 results\n","model_1_results = calculate_results(y_true=val_labels_encoded,\n","                                    y_pred=model_1_preds)\n","model_1_results"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oaVVFVT-fC-E","executionInfo":{"status":"ok","timestamp":1703583531842,"user_tz":-540,"elapsed":12,"user":{"displayName":"Hee Seong Yang","userId":"11765788859671095501"}},"outputId":"0c334795-3215-458b-bbf8-4c2227b64899"},"execution_count":45,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'accuracy': 78.50853965311796,\n"," 'precision': 0.782436820097313,\n"," 'recall': 0.7850853965311797,\n"," 'f1': 0.78266455104507}"]},"metadata":{},"execution_count":45}]},{"cell_type":"markdown","source":["## Model 2: Feature extraction with pretrained token embeddings\n","\n","Training our own embeddings took a little while to run, slowing our experiments down.\n","\n","Since we're moving towards replicating the model architecture in Neural Networks for Joint Sentence Classification in Medical Paper Abstracts, it mentions they used a pretrained GloVe embedding as a way to initialise their token embeddings.\n","\n","To emulate this, let's see what results we can get with the pretrained Universal Sentence Encoder embeddings from TensorFlow Hub.\n","\n","ðŸ”‘ Note: We could use GloVe embeddings as per the paper but since we're working with TensorFlow, we'll use what's available from TensorFlow Hub (GloVe embeddings aren't). We'll save using pretrained GloVe embeddings as an extension.\n","\n","The model structure will look like:\n","\n","Inputs (string) -> Pretrained embeddings from TensorFlow Hub (Universal Sentence Encoder) -> Layers -> Output (prediction probabilities)\n","You'll notice the lack of tokenization layer we've used in a previous model. This is because the Universal Sentence Encoder (USE) takes care of tokenization for us.\n","\n","This type of model is called transfer learning, or more specifically, feature extraction transfer learning. In other words, taking the patterns a model has learned elsewhere and applying it to our own problem."],"metadata":{"id":"Yv7sByU9e9DF"}}]}